


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Index &mdash; TorchRec 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" />
  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torchrec.datasets.html">torchrec.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.datasets.scripts.html">torchrec.datasets.scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.distributed.html">torchrec.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.distributed.planner.html">torchrec.distributed.planner</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.distributed.sharding.html">torchrec.distributed.sharding</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.fx.html">torchrec.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.inference.html">torchrec.inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.models.html">torchrec.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.modules.html">torchrec.modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.optim.html">torchrec.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.quant.html">torchrec.quant</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchrec.sparse.html">torchrec.sparse</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Index</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#C"><strong>C</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#H"><strong>H</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#J"><strong>J</strong></a>
 | <a href="#K"><strong>K</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#O"><strong>O</strong></a>
 | <a href="#P"><strong>P</strong></a>
 | <a href="#Q"><strong>Q</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#V"><strong>V</strong></a>
 | <a href="#W"><strong>W</strong></a>
 | <a href="#Z"><strong>Z</strong></a>
 
</div>
<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.ADAGRAD">ADAGRAD (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.ADAM">ADAM (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizer.add_param_group">add_param_group() (torchrec.optim.keyed.KeyedOptimizer method)</a>

      <ul>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper.add_param_group">(torchrec.optim.keyed.OptimizerWrapper method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.add_prefix_to_state_dict">add_prefix_to_state_dict() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Pooled_Req">All2All_Pooled_Req (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Pooled_Wait">All2All_Pooled_Wait (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Seq_Req">All2All_Seq_Req (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Seq_Req_Wait">All2All_Seq_Req_Wait (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllDenseInfo">All2AllDenseInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllPooledInfo">All2AllPooledInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo">All2AllSequenceInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2Allv_Req">All2Allv_Req (class in torchrec.distributed.comm_ops)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2Allv_Wait">All2Allv_Wait (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo">All2AllVInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.all_gather_base_pooled">all_gather_base_pooled() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBase_Req">AllGatherBase_Req (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBase_Wait">AllGatherBase_Wait (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBaseInfo">AllGatherBaseInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.alltoall_pooled">alltoall_pooled() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.alltoall_sequence">alltoall_sequence() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.alltoallv">alltoallv() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.append_prefix">append_prefix() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.lazy_extension.LazyModuleExtensionMixin.apply">apply() (torchrec.modules.lazy_extension.LazyModuleExtensionMixin method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.ArgInfo">ArgInfo (class in torchrec.distributed.train_pipeline)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.PipelinedForward.args">args (torchrec.distributed.train_pipeline.PipelinedForward property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.Awaitable">Awaitable (class in torchrec.distributed.types)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#id12">B_global (torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.B_global">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllPooledInfo.B_local">B_local (torchrec.distributed.comm_ops.All2AllPooledInfo attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.html#id13">(torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.B_local">[1]</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id14">B_local_list (torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.B_local_list">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodecs.backward">backward (torchrec.distributed.types.QuantizedCommCodecs attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Pooled_Req.backward">backward() (torchrec.distributed.comm_ops.All2All_Pooled_Req static method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Pooled_Wait.backward">(torchrec.distributed.comm_ops.All2All_Pooled_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Seq_Req.backward">(torchrec.distributed.comm_ops.All2All_Seq_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Seq_Req_Wait.backward">(torchrec.distributed.comm_ops.All2All_Seq_Req_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2Allv_Req.backward">(torchrec.distributed.comm_ops.All2Allv_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2Allv_Wait.backward">(torchrec.distributed.comm_ops.All2Allv_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBase_Req.backward">(torchrec.distributed.comm_ops.AllGatherBase_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBase_Wait.backward">(torchrec.distributed.comm_ops.AllGatherBase_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatter_Req.backward">(torchrec.distributed.comm_ops.ReduceScatter_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatter_Wait.backward">(torchrec.distributed.comm_ops.ReduceScatter_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBase_Req.backward">(torchrec.distributed.comm_ops.ReduceScatterBase_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBase_Wait.backward">(torchrec.distributed.comm_ops.ReduceScatterBase_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterV_Req.backward">(torchrec.distributed.comm_ops.ReduceScatterV_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterV_Wait.backward">(torchrec.distributed.comm_ops.ReduceScatterV_Wait static method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id4">backward_recat_tensor (torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.backward_recat_tensor">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.bare_named_parameters">bare_named_parameters() (torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.cw_sharding.BaseCwEmbeddingSharding">BaseCwEmbeddingSharding (class in torchrec.distributed.sharding.cw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding">BaseDpEmbeddingSharding (class in torchrec.distributed.sharding.dp_sharding)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig">BaseEmbeddingConfig (class in torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.BaseEmbeddingDist">BaseEmbeddingDist (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingLookup">BaseEmbeddingLookup (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingSharder">BaseEmbeddingSharder (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.BaseFeatureProcessor">BaseFeatureProcessor (class in torchrec.modules.feature_processor)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseGroupedFeatureProcessor">BaseGroupedFeatureProcessor (class in torchrec.distributed.embedding_types)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.BaseGroupedFeatureProcessor">(class in torchrec.modules.feature_processor)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder">BaseQuantEmbeddingSharder (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding">BaseRwEmbeddingSharding (class in torchrec.distributed.sharding.rw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.BaseSparseFeaturesDist">BaseSparseFeaturesDist (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding">BaseTwEmbeddingSharding (class in torchrec.distributed.sharding.tw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding">BaseTwRwEmbeddingSharding (class in torchrec.distributed.sharding.twrw_sharding)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Batch">Batch (class in torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllDenseInfo.batch_size">batch_size (torchrec.distributed.comm_ops.All2AllDenseInfo attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#id0">batch_size_per_rank (torchrec.distributed.comm_ops.All2AllPooledInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllPooledInfo.batch_size_per_rank">[1]</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingContext.batch_size_per_rank">(torchrec.distributed.embedding_sharding.EmbeddingShardingContext attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints.batch_sizes">batch_sizes (torchrec.distributed.planner.types.ParameterConstraints attribute)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.batching_metadata">batching_metadata() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.batching_metadata_json">batching_metadata_json() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.BatchingMetadata">BatchingMetadata (class in torchrec.inference.modules)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.BinaryCriteoUtils">BinaryCriteoUtils (class in torchrec.datasets.criteo)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.bucketize_kjt_before_all2all">bucketize_kjt_before_all2all() (in module torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.utils.bytes_to_gb">bytes_to_gb() (in module torchrec.distributed.planner.utils)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.utils.bytes_to_mb">bytes_to_mb() (in module torchrec.distributed.planner.utils)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="C">C</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NoOpQuantizedCommCodec.calc_quantized_size">calc_quantized_size() (torchrec.distributed.types.NoOpQuantizedCommCodec method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodec.calc_quantized_size">(torchrec.distributed.types.QuantizedCommCodec method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.shard_estimators.calculate_shard_storages">calculate_shard_storages() (in module torchrec.distributed.planner.shard_estimators)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll.callbacks">callbacks (torchrec.distributed.dist_data.PooledEmbeddingsAllToAll property)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll.callbacks">[1]</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAwaitable.callbacks">(torchrec.distributed.dist_data.PooledEmbeddingsAwaitable property)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAwaitable.callbacks">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.Awaitable.callbacks">(torchrec.distributed.types.Awaitable property)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.utils.check_module_output_dimension">check_module_output_dimension() (in module torchrec.modules.utils)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.choose">choose() (in module torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllPooledInfo.codecs">codecs (torchrec.distributed.comm_ops.All2AllPooledInfo attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.codecs">(torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.codecs">(torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBaseInfo.codecs">(torchrec.distributed.comm_ops.AllGatherBaseInfo attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBaseInfo.codecs">(torchrec.distributed.comm_ops.ReduceScatterBaseInfo attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterInfo.codecs">(torchrec.distributed.comm_ops.ReduceScatterInfo attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterVInfo.codecs">(torchrec.distributed.comm_ops.ReduceScatterVInfo attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.planners.EmbeddingShardingPlanner.collective_plan">collective_plan() (torchrec.distributed.planner.planners.EmbeddingShardingPlanner method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingPlanner.collective_plan">(torchrec.distributed.types.ShardingPlanner method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingType.COLUMN_WISE">COLUMN_WISE (torchrec.distributed.types.ShardingType attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer">CombinedOptimizer (class in torchrec.optim.keyed)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.CommOp">CommOp (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection.compute">compute() (torchrec.distributed.embedding.ShardedEmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.compute">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection.compute">(torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.compute">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.compute">(torchrec.distributed.types.ShardedModule method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection.compute_and_output_dist">compute_and_output_dist() (torchrec.distributed.embedding.ShardedEmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection.compute_and_output_dist">(torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.compute_and_output_dist">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.compute_and_output_dist">(torchrec.distributed.types.ShardedModule method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.compute_device">compute_device (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingAttributes.compute_kernel">compute_kernel (torchrec.distributed.embedding_types.EmbeddingAttributes attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.compute_kernel">(torchrec.distributed.embedding_types.GroupedEmbeddingConfig attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterSharding.compute_kernel">(torchrec.distributed.types.ParameterSharding attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.compute_kernel_to_embedding_location">compute_kernel_to_embedding_location() (in module torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints.compute_kernels">compute_kernels (torchrec.distributed.planner.types.ParameterConstraints attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingSharder.compute_kernels">compute_kernels() (torchrec.distributed.embedding_types.BaseEmbeddingSharder method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder.compute_kernels">(torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder.compute_kernels">(torchrec.distributed.types.ModuleSharder method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ComputeKernel">ComputeKernel (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.ComputeKJTToJTDict">ComputeKJTToJTDict (class in torchrec.sparse.jagged_tensor)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.concat">concat() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor static method)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupPolicy.CONSTANT">CONSTANT (torchrec.optim.warmup.WarmupPolicy attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.utils.construct_modulelist_from_single_module">construct_modulelist_from_single_module() (in module torchrec.modules.utils)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.utils.convert_list_of_modules_to_modulelist">convert_list_of_modules_to_modulelist() (in module torchrec.modules.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.copy">copy() (torchrec.distributed.model_parallel.DistributedModelParallel method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.copy">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.utils.CopyableMixin.copy">(torchrec.distributed.utils.CopyableMixin method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.copy_to_device">copy_to_device() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.CopyableMixin">CopyableMixin (class in torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.create_arg">create_arg() (torchrec.fx.tracer.Tracer method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection.create_context">create_context() (torchrec.distributed.embedding.ShardedEmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.create_context">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection.create_context">(torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.create_context">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.NoOpQuantizedCommCodec.create_context">(torchrec.distributed.types.NoOpQuantizedCommCodec method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodec.create_context">(torchrec.distributed.types.QuantizedCommCodec method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.create_context">(torchrec.distributed.types.ShardedModule method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.create_embedding_bag_sharding">create_embedding_bag_sharding() (in module torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.create_embedding_sharding">create_embedding_sharding() (in module torchrec.distributed.embedding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.create_infer_embedding_bag_sharding">create_infer_embedding_bag_sharding() (in module torchrec.distributed.quant_embeddingbag)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.create_input_dist">create_input_dist() (torchrec.distributed.embedding_sharding.EmbeddingSharding method)</a>

      <ul>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.cw_sharding.CwPooledEmbeddingSharding.create_input_dist">(torchrec.distributed.sharding.cw_sharding.CwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingSharding.create_input_dist">(torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingSharding.create_input_dist">(torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwEmbeddingSharding.create_input_dist">(torchrec.distributed.sharding.tw_sharding.InferTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding.create_input_dist">(torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingSharding.create_input_dist">(torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.create_lookup">create_lookup() (torchrec.distributed.embedding_sharding.EmbeddingSharding method)</a>

      <ul>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.cw_sharding.CwPooledEmbeddingSharding.create_lookup">(torchrec.distributed.sharding.cw_sharding.CwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingSharding.create_lookup">(torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingSharding.create_lookup">(torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwEmbeddingSharding.create_lookup">(torchrec.distributed.sharding.tw_sharding.InferTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding.create_lookup">(torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingSharding.create_lookup">(torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.create_output_dist">create_output_dist() (torchrec.distributed.embedding_sharding.EmbeddingSharding method)</a>

      <ul>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.cw_sharding.CwPooledEmbeddingSharding.create_output_dist">(torchrec.distributed.sharding.cw_sharding.CwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingSharding.create_output_dist">(torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingSharding.create_output_dist">(torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwEmbeddingSharding.create_output_dist">(torchrec.distributed.sharding.tw_sharding.InferTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding.create_output_dist">(torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingSharding.create_output_dist">(torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.create_predict_module">create_predict_module() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.create_sharding_infos_by_sharding">create_sharding_infos_by_sharding() (in module torchrec.distributed.embedding)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.create_sharding_infos_by_sharding">(in module torchrec.distributed.embeddingbag)</a>
</li>
      </ul></li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.criteo_kaggle">criteo_kaggle() (in module torchrec.datasets.criteo)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.criteo_terabyte">criteo_terabyte() (in module torchrec.datasets.criteo)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.CriteoIterDataPipe">CriteoIterDataPipe (class in torchrec.datasets.criteo)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.crossnet.CrossNet">CrossNet (class in torchrec.modules.crossnet)</a>
</li>
      <li><a href="torchrec.distributed.html#id1">cumsum_dim_sum_per_rank_tensor (torchrec.distributed.comm_ops.All2AllPooledInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllPooledInfo.cumsum_dim_sum_per_rank_tensor">[1]</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.cw_sharding.CwPooledEmbeddingSharding">CwPooledEmbeddingSharding (class in torchrec.distributed.sharding.cw_sharding)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#id15">D_local_list (torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.D_local_list">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingType.DATA_PARALLEL">DATA_PARALLEL (torchrec.distributed.types.ShardingType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.data_type">data_type (torchrec.distributed.embedding_types.GroupedEmbeddingConfig attribute)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.data_type">(torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.data_type_to_dtype">data_type_to_dtype() (in module torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.data_type_to_sparse_type">data_type_to_sparse_type() (in module torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DataParallelWrapper">DataParallelWrapper (class in torchrec.distributed.model_parallel)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType">DataType (class in torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Storage.ddr">ddr (torchrec.distributed.planner.types.Storage attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterStorage.DDR">DDR (torchrec.distributed.types.ParameterStorage attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.ddr_mem_bw">ddr_mem_bw (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupStage.decay_iters">decay_iters (torchrec.optim.warmup.WarmupStage attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NoOpQuantizedCommCodec.decode">decode() (torchrec.distributed.types.NoOpQuantizedCommCodec method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodec.decode">(torchrec.distributed.types.QuantizedCommCodec method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.deepfm.DeepFM">DeepFM (class in torchrec.modules.deepfm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ComputeKernel.DEFAULT">DEFAULT (torchrec.distributed.types.ComputeKernel attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DefaultDataParallelWrapper">DefaultDataParallelWrapper (class in torchrec.distributed.model_parallel)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel.DENSE">DENSE (torchrec.distributed.embedding_types.EmbeddingComputeKernel attribute)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Batch.dense_features">dense_features (torchrec.datasets.utils.Batch attribute)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.deepfm.DenseArch">DenseArch (class in torchrec.models.deepfm)</a>

      <ul>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DenseArch">(class in torchrec.models.dlrm)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PartitionByType.DEVICE">DEVICE (torchrec.distributed.planner.types.PartitionByType attribute)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.BatchingMetadata.device">device (torchrec.inference.modules.BatchingMetadata attribute)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollection.device">(torchrec.modules.embedding_modules.EmbeddingBagCollection property)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection.device">(torchrec.modules.embedding_modules.EmbeddingCollection property)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection.device">(torchrec.quant.embedding_modules.EmbeddingBagCollection property)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.device">(torchrec.quant.embedding_modules.EmbeddingCollection property)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.device">device() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.DeviceHardware">DeviceHardware (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.devices">devices (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.dim_sum">dim_sum() (torchrec.distributed.embedding_types.GroupedEmbeddingConfig method)</a>
</li>
      <li><a href="torchrec.distributed.html#id2">dim_sum_per_rank (torchrec.distributed.comm_ops.All2AllPooledInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllPooledInfo.dim_sum_per_rank">[1]</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.dim_sum_per_rank">(torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id3">dim_sum_per_rank_tensor (torchrec.distributed.comm_ops.All2AllPooledInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllPooledInfo.dim_sum_per_rank_tensor">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.dims_sum_per_rank">dims_sum_per_rank (torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.dist_init">dist_init() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor static method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.dist_labels">dist_labels() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.dist_splits">dist_splits() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.dist_tensors">dist_tensors() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel">DistributedModelParallel (class in torchrec.distributed.model_parallel)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM">DLRM (class in torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM_DCN">DLRM_DCN (class in torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM_Projection">DLRM_Projection (class in torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRMTrain">DLRMTrain (class in torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingDist">DpPooledEmbeddingDist (class in torchrec.distributed.sharding.dp_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingSharding">DpPooledEmbeddingSharding (class in torchrec.distributed.sharding.dp_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpSparseFeaturesDist">DpSparseFeaturesDist (class in torchrec.distributed.sharding.dp_sharding)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.dtype_to_data_type">dtype_to_data_type() (in module torchrec.modules.embedding_configs)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollection.embedding_bag_configs">embedding_bag_configs() (torchrec.modules.embedding_modules.EmbeddingBagCollection method)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface.embedding_bag_configs">(torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection.embedding_bag_configs">(torchrec.quant.embedding_modules.EmbeddingBagCollection method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingInfo.embedding_config">embedding_config (torchrec.distributed.embedding_sharding.EmbeddingShardingInfo attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection.embedding_configs">embedding_configs() (torchrec.modules.embedding_modules.EmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollectionInterface.embedding_configs">(torchrec.modules.embedding_modules.EmbeddingCollectionInterface method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.embedding_configs">(torchrec.quant.embedding_modules.EmbeddingCollection method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id5">embedding_dim (torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.embedding_dim">[1]</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.embedding_dim">(torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingConfig.embedding_dim">(torchrec.modules.embedding_configs.EmbeddingConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection.embedding_dim">embedding_dim() (torchrec.modules.embedding_modules.EmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollectionInterface.embedding_dim">(torchrec.modules.embedding_modules.EmbeddingCollectionInterface method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.embedding_dim">(torchrec.quant.embedding_modules.EmbeddingCollection method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.embedding_dims">embedding_dims() (torchrec.distributed.embedding_sharding.EmbeddingSharding method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.embedding_dims">(torchrec.distributed.embedding_types.GroupedEmbeddingConfig method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.cw_sharding.BaseCwEmbeddingSharding.embedding_dims">(torchrec.distributed.sharding.cw_sharding.BaseCwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding.embedding_dims">(torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding.embedding_dims">(torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding.embedding_dims">(torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding.embedding_dims">(torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingTableConfig.embedding_names">embedding_names (torchrec.modules.embedding_configs.EmbeddingTableConfig attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.embedding_names">embedding_names() (torchrec.distributed.embedding_sharding.EmbeddingSharding method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.embedding_names">(torchrec.distributed.embedding_types.GroupedEmbeddingConfig method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.cw_sharding.BaseCwEmbeddingSharding.embedding_names">(torchrec.distributed.sharding.cw_sharding.BaseCwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding.embedding_names">(torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding.embedding_names">(torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding.embedding_names">(torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding.embedding_names">(torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection.embedding_names_by_table">embedding_names_by_table() (torchrec.modules.embedding_modules.EmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollectionInterface.embedding_names_by_table">(torchrec.modules.embedding_modules.EmbeddingCollectionInterface method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.embedding_names_by_table">(torchrec.quant.embedding_modules.EmbeddingCollection method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.embedding_names_per_rank">embedding_names_per_rank() (torchrec.distributed.embedding_sharding.EmbeddingSharding method)</a>

      <ul>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding.embedding_names_per_rank">(torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding.embedding_names_per_rank">(torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding.embedding_names_per_rank">(torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding.embedding_names_per_rank">(torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.embedding_shard_metadata">embedding_shard_metadata() (torchrec.distributed.embedding_sharding.EmbeddingSharding method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.embedding_shard_metadata">(torchrec.distributed.embedding_types.GroupedEmbeddingConfig method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding.embedding_shard_metadata">(torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding.embedding_shard_metadata">(torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding.embedding_shard_metadata">(torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding.embedding_shard_metadata">(torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.embedding_tables">embedding_tables (torchrec.distributed.embedding_types.GroupedEmbeddingConfig attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingAttributes">EmbeddingAttributes (class in torchrec.distributed.embedding_types)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingAwaitable">EmbeddingAwaitable (class in torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollection">EmbeddingBagCollection (class in torchrec.modules.embedding_modules)</a>

      <ul>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection">(class in torchrec.quant.embedding_modules)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionAwaitable">EmbeddingBagCollectionAwaitable (class in torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionContext">EmbeddingBagCollectionContext (class in torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface">EmbeddingBagCollectionInterface (class in torchrec.modules.embedding_modules)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder">EmbeddingBagCollectionSharder (class in torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingBagConfig">EmbeddingBagConfig (class in torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagSharder">EmbeddingBagSharder (class in torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection">EmbeddingCollection (class in torchrec.modules.embedding_modules)</a>

      <ul>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection">(class in torchrec.quant.embedding_modules)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionAwaitable">EmbeddingCollectionAwaitable (class in torchrec.distributed.embedding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionContext">EmbeddingCollectionContext (class in torchrec.distributed.embedding)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollectionInterface">EmbeddingCollectionInterface (class in torchrec.modules.embedding_modules)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionSharder">EmbeddingCollectionSharder (class in torchrec.distributed.embedding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel">EmbeddingComputeKernel (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingConfig">EmbeddingConfig (class in torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.enumerators.EmbeddingEnumerator">EmbeddingEnumerator (class in torchrec.distributed.planner.enumerators)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.EmbeddingModuleShardingPlan">EmbeddingModuleShardingPlan (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.shard_estimators.EmbeddingPerfEstimator">EmbeddingPerfEstimator (class in torchrec.distributed.planner.shard_estimators)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.embeddings_cat_empty_rank_handle">embeddings_cat_empty_rank_handle() (in module torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.EmbeddingsAllToOne">EmbeddingsAllToOne (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.EmbeddingsAllToOne">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding">EmbeddingSharding (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingContext">EmbeddingShardingContext (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingInfo">EmbeddingShardingInfo (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.planners.EmbeddingShardingPlanner">EmbeddingShardingPlanner (class in torchrec.distributed.planner.planners)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.stats.EmbeddingStats">EmbeddingStats (class in torchrec.distributed.planner.stats)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.shard_estimators.EmbeddingStorageEstimator">EmbeddingStorageEstimator (class in torchrec.distributed.planner.shard_estimators)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingTableConfig">EmbeddingTableConfig (class in torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.empty">empty() (torchrec.sparse.jagged_tensor.JaggedTensor static method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor static method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.empty_like">empty_like() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor static method)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.fused.EmptyFusedOptimizer">EmptyFusedOptimizer (class in torchrec.optim.fused)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NoOpQuantizedCommCodec.encode">encode() (torchrec.distributed.types.NoOpQuantizedCommCodec method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodec.encode">(torchrec.distributed.types.QuantizedCommCodec method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.enumerators.EmbeddingEnumerator.enumerate">enumerate() (torchrec.distributed.planner.enumerators.EmbeddingEnumerator method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Enumerator.enumerate">(torchrec.distributed.planner.types.Enumerator method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Enumerator">Enumerator (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterVInfo.equal_splits">equal_splits (torchrec.distributed.comm_ops.ReduceScatterVInfo attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.shard_estimators.EmbeddingPerfEstimator.estimate">estimate() (torchrec.distributed.planner.shard_estimators.EmbeddingPerfEstimator method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.shard_estimators.EmbeddingStorageEstimator.estimate">(torchrec.distributed.planner.shard_estimators.EmbeddingStorageEstimator method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardEstimator.estimate">(torchrec.distributed.planner.types.ShardEstimator method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedEmbeddingModule.extra_repr">extra_repr() (torchrec.distributed.embedding_types.ShardedEmbeddingModule method)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.utils.extract_module_or_tensor_callable">extract_module_or_tensor_callable() (in module torchrec.modules.utils)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.modules.html#torchrec.modules.deepfm.FactorizationMachine">FactorizationMachine (class in torchrec.modules.deepfm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.feature_hash_sizes">feature_hash_sizes() (torchrec.distributed.embedding_types.GroupedEmbeddingConfig method)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.feature_names">feature_names (torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingConfig.feature_names">(torchrec.modules.embedding_configs.EmbeddingConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.FeatureShardingMixIn.feature_names">feature_names() (torchrec.distributed.embedding_types.FeatureShardingMixIn method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.feature_names">(torchrec.distributed.embedding_types.GroupedEmbeddingConfig method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding.feature_names">(torchrec.distributed.sharding.dp_sharding.BaseDpEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding.feature_names">(torchrec.distributed.sharding.rw_sharding.BaseRwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding.feature_names">(torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding.feature_names">(torchrec.distributed.sharding.twrw_sharding.BaseTwRwEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.FeatureShardingMixIn.feature_names_per_rank">feature_names_per_rank() (torchrec.distributed.embedding_types.FeatureShardingMixIn method)</a>

      <ul>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding.feature_names_per_rank">(torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineContext.feature_processor_forwards">feature_processor_forwards (torchrec.distributed.train_pipeline.TrainPipelineContext attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.FeatureShardingMixIn.features_per_rank">features_per_rank() (torchrec.distributed.embedding_types.FeatureShardingMixIn method)</a>

      <ul>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding.features_per_rank">(torchrec.distributed.sharding.tw_sharding.BaseTwEmbeddingSharding method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.FeatureShardingMixIn">FeatureShardingMixIn (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GreedyProposer.feedback">feedback() (torchrec.distributed.planner.proposers.GreedyProposer method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GridSearchProposer.feedback">(torchrec.distributed.planner.proposers.GridSearchProposer method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.UniformProposer.feedback">(torchrec.distributed.planner.proposers.UniformProposer method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Proposer.feedback">(torchrec.distributed.planner.types.Proposer method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.filter_state_dict">filter_state_dict() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Storage.fits_in">fits_in() (torchrec.distributed.planner.types.Storage method)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.storage_reservations.FixedPercentageStorageReservation">FixedPercentageStorageReservation (class in torchrec.distributed.planner.storage_reservations)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.deepfm.FMInteractionArch">FMInteractionArch (class in torchrec.models.deepfm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodecs.forward">forward (torchrec.distributed.types.QuantizedCommCodecs attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Pooled_Req.forward">forward() (torchrec.distributed.comm_ops.All2All_Pooled_Req static method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Pooled_Wait.forward">(torchrec.distributed.comm_ops.All2All_Pooled_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Seq_Req.forward">(torchrec.distributed.comm_ops.All2All_Seq_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2All_Seq_Req_Wait.forward">(torchrec.distributed.comm_ops.All2All_Seq_Req_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2Allv_Req.forward">(torchrec.distributed.comm_ops.All2Allv_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2Allv_Wait.forward">(torchrec.distributed.comm_ops.All2Allv_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBase_Req.forward">(torchrec.distributed.comm_ops.AllGatherBase_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBase_Wait.forward">(torchrec.distributed.comm_ops.AllGatherBase_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatter_Req.forward">(torchrec.distributed.comm_ops.ReduceScatter_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatter_Wait.forward">(torchrec.distributed.comm_ops.ReduceScatter_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBase_Req.forward">(torchrec.distributed.comm_ops.ReduceScatterBase_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBase_Wait.forward">(torchrec.distributed.comm_ops.ReduceScatterBase_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterV_Req.forward">(torchrec.distributed.comm_ops.ReduceScatterV_Req static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterV_Wait.forward">(torchrec.distributed.comm_ops.ReduceScatterV_Wait static method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.EmbeddingsAllToOne.forward">(torchrec.distributed.dist_data.EmbeddingsAllToOne method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.EmbeddingsAllToOne.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTAllToAll.forward">(torchrec.distributed.dist_data.KJTAllToAll method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTAllToAll.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTOneToAll.forward">(torchrec.distributed.dist_data.KJTOneToAll method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTOneToAll.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAllGather.forward">(torchrec.distributed.dist_data.PooledEmbeddingsAllGather method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAllGather.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll.forward">(torchrec.distributed.dist_data.PooledEmbeddingsAllToAll method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter.forward">(torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SeqEmbeddingsAllToOne.forward">(torchrec.distributed.dist_data.SeqEmbeddingsAllToOne method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SeqEmbeddingsAllToOne.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll.forward">(torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll method)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll.forward">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup.forward">(torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup.forward">(torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedLookupMixin.forward">(torchrec.distributed.embedding_lookup.InferGroupedLookupMixin method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup.forward">(torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup.forward">(torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.BaseEmbeddingDist.forward">(torchrec.distributed.embedding_sharding.BaseEmbeddingDist method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.BaseSparseFeaturesDist.forward">(torchrec.distributed.embedding_sharding.BaseSparseFeaturesDist method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingLookup.forward">(torchrec.distributed.embedding_types.BaseEmbeddingLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseGroupedFeatureProcessor.forward">(torchrec.distributed.embedding_types.BaseGroupedFeatureProcessor method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule.forward">(torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.forward">(torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingDist.forward">(torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpSparseFeaturesDist.forward">(torchrec.distributed.sharding.dp_sharding.DpSparseFeaturesDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingDist.forward">(torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwSparseFeaturesDist.forward">(torchrec.distributed.sharding.rw_sharding.RwSparseFeaturesDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwPooledEmbeddingDist.forward">(torchrec.distributed.sharding.tw_sharding.InferTwPooledEmbeddingDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwSparseFeaturesDist.forward">(torchrec.distributed.sharding.tw_sharding.InferTwSparseFeaturesDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingDist.forward">(torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwSparseFeaturesDist.forward">(torchrec.distributed.sharding.tw_sharding.TwSparseFeaturesDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingDist.forward">(torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingDist method)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwSparseFeaturesDist.forward">(torchrec.distributed.sharding.twrw_sharding.TwRwSparseFeaturesDist method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.forward">(torchrec.distributed.types.ShardedModule method)</a>
</li>
        <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictModule.forward">(torchrec.inference.modules.PredictModule method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.DenseArch.forward">(torchrec.models.deepfm.DenseArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.FMInteractionArch.forward">(torchrec.models.deepfm.FMInteractionArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.OverArch.forward">(torchrec.models.deepfm.OverArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.SimpleDeepFMNN.forward">(torchrec.models.deepfm.SimpleDeepFMNN method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.SparseArch.forward">(torchrec.models.deepfm.SparseArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DenseArch.forward">(torchrec.models.dlrm.DenseArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM.forward">(torchrec.models.dlrm.DLRM method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRMTrain.forward">(torchrec.models.dlrm.DLRMTrain method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionArch.forward">(torchrec.models.dlrm.InteractionArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionDCNArch.forward">(torchrec.models.dlrm.InteractionDCNArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionProjectionArch.forward">(torchrec.models.dlrm.InteractionProjectionArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.OverArch.forward">(torchrec.models.dlrm.OverArch method)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.SparseArch.forward">(torchrec.models.dlrm.SparseArch method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.activation.SwishLayerNorm.forward">(torchrec.modules.activation.SwishLayerNorm method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.CrossNet.forward">(torchrec.modules.crossnet.CrossNet method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.LowRankCrossNet.forward">(torchrec.modules.crossnet.LowRankCrossNet method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.LowRankMixtureCrossNet.forward">(torchrec.modules.crossnet.LowRankMixtureCrossNet method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.VectorCrossNet.forward">(torchrec.modules.crossnet.VectorCrossNet method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.deepfm.DeepFM.forward">(torchrec.modules.deepfm.DeepFM method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.deepfm.FactorizationMachine.forward">(torchrec.modules.deepfm.FactorizationMachine method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollection.forward">(torchrec.modules.embedding_modules.EmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface.forward">(torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection.forward">(torchrec.modules.embedding_modules.EmbeddingCollection method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollectionInterface.forward">(torchrec.modules.embedding_modules.EmbeddingCollectionInterface method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.BaseFeatureProcessor.forward">(torchrec.modules.feature_processor.BaseFeatureProcessor method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.BaseGroupedFeatureProcessor.forward">(torchrec.modules.feature_processor.BaseGroupedFeatureProcessor method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedModule.forward">(torchrec.modules.feature_processor.PositionWeightedModule method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedProcessor.forward">(torchrec.modules.feature_processor.PositionWeightedProcessor method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.mlp.MLP.forward">(torchrec.modules.mlp.MLP method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.mlp.Perceptron.forward">(torchrec.modules.mlp.Perceptron method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection.forward">(torchrec.quant.embedding_modules.EmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.forward">(torchrec.quant.embedding_modules.EmbeddingCollection method)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.ComputeKJTToJTDict.forward">(torchrec.sparse.jagged_tensor.ComputeKJTToJTDict method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#id6">forward_recat_tensor (torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.forward_recat_tensor">[1]</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType.FP16">FP16 (torchrec.modules.embedding_configs.DataType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType.FP32">FP32 (torchrec.modules.embedding_configs.DataType attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.fqn">fqn (torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.from_dense">from_dense() (torchrec.sparse.jagged_tensor.JaggedTensor static method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.from_dense_lengths">from_dense_lengths() (torchrec.sparse.jagged_tensor.JaggedTensor static method)</a>
</li>
      <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection.from_float">from_float() (torchrec.quant.embedding_modules.EmbeddingBagCollection class method)</a>

      <ul>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.from_float">(torchrec.quant.embedding_modules.EmbeddingCollection class method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_jt_dict">from_jt_dict() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor static method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_lengths_sync">from_lengths_sync() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor static method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingEnv.from_local">from_local() (torchrec.distributed.types.ShardingEnv class method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_offsets_sync">from_offsets_sync() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor static method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingEnv.from_process_group">from_process_group() (torchrec.distributed.types.ShardingEnv class method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.from_tensor_list">from_tensor_list() (torchrec.sparse.jagged_tensor.KeyedTensor static method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel.FUSED">FUSED (torchrec.distributed.embedding_types.EmbeddingComputeKernel attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection.fused_optimizer">fused_optimizer (torchrec.distributed.embedding.ShardedEmbeddingCollection property)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.fused_optimizer">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection.fused_optimizer">(torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.fused_optimizer">(torchrec.distributed.model_parallel.DistributedModelParallel property)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.fused.FusedOptimizerModule.fused_optimizer">(torchrec.optim.fused.FusedOptimizerModule property)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingInfo.fused_params">fused_params (torchrec.distributed.embedding_sharding.EmbeddingShardingInfo attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingSharder.fused_params">(torchrec.distributed.embedding_types.BaseEmbeddingSharder property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder.fused_params">(torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.fused_params">(torchrec.distributed.embedding_types.GroupedEmbeddingConfig attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedEmbeddingTable.fused_params">(torchrec.distributed.embedding_types.ShardedEmbeddingTable attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel.FUSED_UVM">FUSED_UVM (torchrec.distributed.embedding_types.EmbeddingComputeKernel attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel.FUSED_UVM_CACHING">FUSED_UVM_CACHING (torchrec.distributed.embedding_types.EmbeddingComputeKernel attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.fused.FusedOptimizer">FusedOptimizer (class in torchrec.optim.fused)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.fused.FusedOptimizerModule">FusedOptimizerModule (class in torchrec.optim.fused)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.fx_wrap_tensor_view2d">fx_wrap_tensor_view2d() (in module torchrec.distributed.embedding_lookup)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.utils.gb_to_bytes">gb_to_bytes() (in module torchrec.distributed.planner.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.GenericMeta">GenericMeta (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.get_embedding_names_by_table">get_embedding_names_by_table() (in module torchrec.modules.embedding_modules)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.BinaryCriteoUtils.get_file_row_ranges_and_remainder">get_file_row_ranges_and_remainder() (torchrec.datasets.criteo.BinaryCriteoUtils static method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm.get_group_rank">get_group_rank() (in module torchrec.distributed.comm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm.get_local_rank">get_local_rank() (in module torchrec.distributed.comm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm.get_local_size">get_local_size() (in module torchrec.distributed.comm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.get_module">get_module() (in module torchrec.distributed.model_parallel)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.utils.get_module_output_dimension">get_module_output_dimension() (in module torchrec.modules.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm.get_num_groups">get_num_groups() (in module torchrec.distributed.comm)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.enumerators.get_partition_by_type">get_partition_by_type() (in module torchrec.distributed.planner.enumerators)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingPlan.get_plan_for_module">get_plan_for_module() (torchrec.distributed.types.ShardingPlan method)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.BinaryCriteoUtils.get_shape_from_npy">get_shape_from_npy() (torchrec.datasets.criteo.BinaryCriteoUtils static method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.get_unsharded_module_names">get_unsharded_module_names() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.get_unwrapped_module">get_unwrapped_module() (in module torchrec.distributed.model_parallel)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.get_weight_init_max">get_weight_init_max() (torchrec.modules.embedding_configs.BaseEmbeddingConfig method)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.get_weight_init_min">get_weight_init_min() (torchrec.modules.embedding_configs.BaseEmbeddingConfig method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedMetaConfig.global_metadata">global_metadata (torchrec.distributed.embedding_types.ShardedMetaConfig attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.clipping.GradientClipping">GradientClipping (class in torchrec.optim.clipping)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.clipping.GradientClippingOptimizer">GradientClippingOptimizer (class in torchrec.optim.clipping)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.Tracer.graph">graph (torchrec.distributed.train_pipeline.Tracer attribute)</a>

      <ul>
        <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.graph">(torchrec.fx.tracer.Tracer attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.partitioners.GreedyPerfPartitioner">GreedyPerfPartitioner (class in torchrec.distributed.planner.partitioners)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GreedyProposer">GreedyProposer (class in torchrec.distributed.planner.proposers)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GridSearchProposer">GridSearchProposer (class in torchrec.distributed.planner.proposers)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.group_tables">group_tables() (in module torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig">GroupedEmbeddingConfig (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup">GroupedEmbeddingsLookup (class in torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup">GroupedPooledEmbeddingsLookup (class in torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule">GroupedPositionWeightedModule (class in torchrec.distributed.grouped_position_weighted)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="H">H</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.has_feature_processor">has_feature_processor (torchrec.distributed.embedding_types.GroupedEmbeddingConfig attribute)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingTableConfig.has_feature_processor">(torchrec.modules.embedding_configs.EmbeddingTableConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Storage.hbm">hbm (torchrec.distributed.planner.types.Storage attribute)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterStorage.HBM">HBM (torchrec.distributed.types.ParameterStorage attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.hbm_mem_bw">hbm_mem_bw (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.storage_reservations.HeuristicalStorageReservation">HeuristicalStorageReservation (class in torchrec.distributed.planner.storage_reservations)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PartitionByType.HOST">HOST (torchrec.distributed.planner.types.PartitionByType attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.idx_split_train_val">idx_split_train_val() (in module torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.storage_reservations.InferenceStorageReservation">InferenceStorageReservation (class in torchrec.distributed.planner.storage_reservations)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedEmbeddingsLookup">InferGroupedEmbeddingsLookup (class in torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedLookupMixin">InferGroupedLookupMixin (class in torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedPooledEmbeddingsLookup">InferGroupedPooledEmbeddingsLookup (class in torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwEmbeddingSharding">InferTwEmbeddingSharding (class in torchrec.distributed.sharding.tw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwPooledEmbeddingDist">InferTwPooledEmbeddingDist (class in torchrec.distributed.sharding.tw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwSparseFeaturesDist">InferTwSparseFeaturesDist (class in torchrec.distributed.sharding.tw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.init_data_parallel">init_data_parallel() (torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.utils.init_mlp_weights_xavier_uniform">init_mlp_weights_xavier_uniform() (in module torchrec.modules.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.init_parameters">init_parameters() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizer.init_state">init_state() (torchrec.optim.keyed.KeyedOptimizer method)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.InMemoryBinaryCriteoIterDataPipe">InMemoryBinaryCriteoIterDataPipe (class in torchrec.datasets.criteo)</a>
</li>
      <li><a href="torchrec.distributed.html#id24">input_attrs (torchrec.distributed.train_pipeline.ArgInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.ArgInfo.input_attrs">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection.input_dist">input_dist() (torchrec.distributed.embedding.ShardedEmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.input_dist">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection.input_dist">(torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.input_dist">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.input_dist">(torchrec.distributed.types.ShardedModule method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineContext.input_dist_requests">input_dist_requests (torchrec.distributed.train_pipeline.TrainPipelineContext attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllDenseInfo.input_shape">input_shape (torchrec.distributed.comm_ops.All2AllDenseInfo attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#id18">input_size (torchrec.distributed.comm_ops.AllGatherBaseInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.AllGatherBaseInfo.input_size">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#id19">input_sizes (torchrec.distributed.comm_ops.ReduceScatterBaseInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBaseInfo.input_sizes">[1]</a>

      <ul>
        <li><a href="torchrec.distributed.html#id20">(torchrec.distributed.comm_ops.ReduceScatterInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterInfo.input_sizes">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#id21">(torchrec.distributed.comm_ops.ReduceScatterVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterVInfo.input_sizes">[1]</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id16">input_split_sizes (torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.input_split_sizes">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllDenseInfo.input_splits">input_splits (torchrec.distributed.comm_ops.All2AllDenseInfo attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.html#id7">(torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.input_splits">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#id22">(torchrec.distributed.comm_ops.ReduceScatterVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterVInfo.input_splits">[1]</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PlannerErrorType.INSUFFICIENT_STORAGE">INSUFFICIENT_STORAGE (torchrec.distributed.planner.types.PlannerErrorType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType.INT2">INT2 (torchrec.modules.embedding_configs.DataType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType.INT32">INT32 (torchrec.modules.embedding_configs.DataType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType.INT4">INT4 (torchrec.modules.embedding_configs.DataType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType.INT64">INT64 (torchrec.modules.embedding_configs.DataType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.DataType.INT8">INT8 (torchrec.modules.embedding_configs.DataType attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.inter_host_bw">inter_host_bw (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionArch">InteractionArch (class in torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionDCNArch">InteractionDCNArch (class in torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionProjectionArch">InteractionProjectionArch (class in torchrec.models.dlrm)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm.intra_and_cross_node_pg">intra_and_cross_node_pg() (in module torchrec.distributed.comm)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.intra_host_bw">intra_host_bw (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.collective_utils.invoke_on_rank_and_broadcast_result">invoke_on_rank_and_broadcast_result() (in module torchrec.distributed.collective_utils)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupPolicy.INVSQRT">INVSQRT (torchrec.optim.warmup.WarmupPolicy attribute)</a>
</li>
      <li><a href="torchrec.fx.html#torchrec.fx.tracer.is_fx_tracing">is_fx_tracing() (in module torchrec.fx.tracer)</a>
</li>
      <li><a href="torchrec.distributed.html#id25">is_getitems (torchrec.distributed.train_pipeline.ArgInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.ArgInfo.is_getitems">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.collective_utils.is_leader">is_leader() (in module torchrec.distributed.collective_utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.Tracer.is_leaf_module">is_leaf_module() (torchrec.distributed.train_pipeline.Tracer method)</a>

      <ul>
        <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.is_leaf_module">(torchrec.fx.tracer.Tracer method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.is_pooled">is_pooled (torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.is_weighted">is_weighted (torchrec.distributed.embedding_types.GroupedEmbeddingConfig attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints.is_weighted">(torchrec.distributed.planner.types.ParameterConstraints attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingTableConfig.is_weighted">(torchrec.modules.embedding_configs.EmbeddingTableConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollection.is_weighted">is_weighted() (torchrec.modules.embedding_modules.EmbeddingBagCollection method)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface.is_weighted">(torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection.is_weighted">(torchrec.quant.embedding_modules.EmbeddingBagCollection method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="J">J</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor">JaggedTensor (class in torchrec.sparse.jagged_tensor)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensorMeta">JaggedTensorMeta (class in torchrec.sparse.jagged_tensor)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="K">K</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.constants.kernel_bw_lookup">kernel_bw_lookup() (in module torchrec.distributed.planner.constants)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.key_dim">key_dim() (torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor">KeyedJaggedTensor (class in torchrec.sparse.jagged_tensor)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizer">KeyedOptimizer (class in torchrec.optim.keyed)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizerWrapper">KeyedOptimizerWrapper (class in torchrec.optim.keyed)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor">KeyedTensor (class in torchrec.sparse.jagged_tensor)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.keys">keys() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.keys">(torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTAllToAll">KJTAllToAll (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTAllToAll">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTAllToAllSplitsAwaitable">KJTAllToAllSplitsAwaitable (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTAllToAllSplitsAwaitable">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTAllToAllTensorsAwaitable">KJTAllToAllTensorsAwaitable (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTAllToAllTensorsAwaitable">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.KJTList">KJTList (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.KJTListAwaitable">KJTListAwaitable (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.KJTListSplitsAwaitable">KJTListSplitsAwaitable (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTOneToAll">KJTOneToAll (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTOneToAll">[1]</a>
</li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Batch.labels">labels (torchrec.datasets.utils.Batch attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.LAMB">LAMB (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.LARS_SGD">LARS_SGD (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.lazy_extension.lazy_apply">lazy_apply() (in module torchrec.modules.lazy_extension)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.LazyAwaitable">LazyAwaitable (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.lazy_extension.LazyModuleExtensionMixin">LazyModuleExtensionMixin (class in torchrec.modules.lazy_extension)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.LazyNoWait">LazyNoWait (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key">length_per_key() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.length_per_key">(torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.length_per_key_or_none">length_per_key_or_none() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.lengths">lengths() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id8">lengths_after_sparse_data_all2all (torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.lengths_after_sparse_data_all2all">[1]</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.lengths_or_none">lengths_or_none() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.lengths_or_none">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Limit">Limit (class in torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupPolicy.LINEAR">LINEAR (torchrec.optim.warmup.WarmupPolicy attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ListOfKJTList">ListOfKJTList (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.ListOfKJTListAwaitable">ListOfKJTListAwaitable (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.ListOfKJTListSplitsAwaitable">ListOfKJTListSplitsAwaitable (class in torchrec.distributed.embedding_sharding)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GreedyProposer.load">load() (torchrec.distributed.planner.proposers.GreedyProposer method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GridSearchProposer.load">(torchrec.distributed.planner.proposers.GridSearchProposer method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.UniformProposer.load">(torchrec.distributed.planner.proposers.UniformProposer method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Proposer.load">(torchrec.distributed.planner.types.Proposer method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.inference.html#torchrec.inference.model_packager.load_config_text">load_config_text() (in module torchrec.inference.model_packager)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.BinaryCriteoUtils.load_npy_range">load_npy_range() (torchrec.datasets.criteo.BinaryCriteoUtils static method)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.model_packager.load_pickle_config">load_pickle_config() (in module torchrec.inference.model_packager)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup.load_state_dict">load_state_dict() (torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup.load_state_dict">(torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedLookupMixin.load_state_dict">(torchrec.distributed.embedding_lookup.InferGroupedLookupMixin method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup.load_state_dict">(torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup.load_state_dict">(torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.load_state_dict">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.load_state_dict">(torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizer.load_state_dict">(torchrec.optim.keyed.KeyedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper.load_state_dict">(torchrec.optim.keyed.OptimizerWrapper method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.LoadFiles">LoadFiles (class in torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedConfig.local_cols">local_cols (torchrec.distributed.embedding_types.ShardedConfig attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedMetaConfig.local_metadata">local_metadata (torchrec.distributed.embedding_types.ShardedMetaConfig attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedConfig.local_rows">local_rows (torchrec.distributed.embedding_types.ShardedConfig attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.local_world_size">local_world_size (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.stats.EmbeddingStats.log">log() (torchrec.distributed.planner.stats.EmbeddingStats method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Stats.log">(torchrec.distributed.planner.types.Stats method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.crossnet.LowRankCrossNet">LowRankCrossNet (class in torchrec.modules.crossnet)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.crossnet.LowRankMixtureCrossNet">LowRankMixtureCrossNet (class in torchrec.modules.crossnet)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupStage.lr_scale">lr_scale (torchrec.optim.warmup.WarmupStage attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.datasets.scripts.html#torchrec.datasets.scripts.contiguous_preproc_criteo.main">main() (in module torchrec.datasets.scripts.contiguous_preproc_criteo)</a>

      <ul>
        <li><a href="torchrec.datasets.scripts.html#torchrec.datasets.scripts.npy_preproc_criteo.main">(in module torchrec.datasets.scripts.npy_preproc_criteo)</a>
</li>
      </ul></li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupStage.max_iters">max_iters (torchrec.optim.warmup.WarmupStage attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.PoolingType.MEAN">MEAN (torchrec.modules.embedding_configs.PoolingType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.merge_fused_params">merge_fused_params() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup">MetaInferGroupedEmbeddingsLookup (class in torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup">MetaInferGroupedPooledEmbeddingsLookup (class in torchrec.distributed.embedding_lookup)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints.min_partition">min_partition (torchrec.distributed.planner.types.ParameterConstraints attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.mlp.MLP">MLP (class in torchrec.modules.mlp)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.model_inputs_data">model_inputs_data() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li>
    module

      <ul>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets">torchrec.datasets</a>
</li>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.criteo">torchrec.datasets.criteo</a>
</li>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.movielens">torchrec.datasets.movielens</a>
</li>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.random">torchrec.datasets.random</a>
</li>
        <li><a href="torchrec.datasets.scripts.html#module-torchrec.datasets.scripts">torchrec.datasets.scripts</a>
</li>
        <li><a href="torchrec.datasets.scripts.html#module-torchrec.datasets.scripts.contiguous_preproc_criteo">torchrec.datasets.scripts.contiguous_preproc_criteo</a>
</li>
        <li><a href="torchrec.datasets.scripts.html#module-torchrec.datasets.scripts.npy_preproc_criteo">torchrec.datasets.scripts.npy_preproc_criteo</a>
</li>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.utils">torchrec.datasets.utils</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed">torchrec.distributed</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.collective_utils">torchrec.distributed.collective_utils</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.comm">torchrec.distributed.comm</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.comm_ops">torchrec.distributed.comm_ops</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.dist_data">torchrec.distributed.dist_data</a>, <a href="torchrec.distributed.sharding.html#module-torchrec.distributed.dist_data">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding">torchrec.distributed.embedding</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding_lookup">torchrec.distributed.embedding_lookup</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding_sharding">torchrec.distributed.embedding_sharding</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding_types">torchrec.distributed.embedding_types</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embeddingbag">torchrec.distributed.embeddingbag</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.grouped_position_weighted">torchrec.distributed.grouped_position_weighted</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.model_parallel">torchrec.distributed.model_parallel</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner">torchrec.distributed.planner</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.constants">torchrec.distributed.planner.constants</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.enumerators">torchrec.distributed.planner.enumerators</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.partitioners">torchrec.distributed.planner.partitioners</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.perf_models">torchrec.distributed.planner.perf_models</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.planners">torchrec.distributed.planner.planners</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.proposers">torchrec.distributed.planner.proposers</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.shard_estimators">torchrec.distributed.planner.shard_estimators</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.stats">torchrec.distributed.planner.stats</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.storage_reservations">torchrec.distributed.planner.storage_reservations</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.types">torchrec.distributed.planner.types</a>
</li>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.utils">torchrec.distributed.planner.utils</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.quant_embeddingbag">torchrec.distributed.quant_embeddingbag</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding">torchrec.distributed.sharding</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.cw_sharding">torchrec.distributed.sharding.cw_sharding</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.dp_sharding">torchrec.distributed.sharding.dp_sharding</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.rw_sharding">torchrec.distributed.sharding.rw_sharding</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.tw_sharding">torchrec.distributed.sharding.tw_sharding</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.twcw_sharding">torchrec.distributed.sharding.twcw_sharding</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.twrw_sharding">torchrec.distributed.sharding.twrw_sharding</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.train_pipeline">torchrec.distributed.train_pipeline</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.types">torchrec.distributed.types</a>
</li>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.utils">torchrec.distributed.utils</a>
</li>
        <li><a href="torchrec.fx.html#module-0">torchrec.fx</a>, <a href="torchrec.fx.html#module-torchrec.fx">[1]</a>
</li>
        <li><a href="torchrec.fx.html#module-torchrec.fx.tracer">torchrec.fx.tracer</a>
</li>
        <li><a href="torchrec.inference.html#module-0">torchrec.inference</a>, <a href="torchrec.inference.html#module-torchrec.inference">[1]</a>
</li>
        <li><a href="torchrec.inference.html#module-torchrec.inference.model_packager">torchrec.inference.model_packager</a>
</li>
        <li><a href="torchrec.inference.html#module-torchrec.inference.modules">torchrec.inference.modules</a>
</li>
        <li><a href="torchrec.models.html#module-0">torchrec.models</a>, <a href="torchrec.models.html#module-torchrec.models">[1]</a>
</li>
        <li><a href="torchrec.models.html#module-torchrec.models.deepfm">torchrec.models.deepfm</a>
</li>
        <li><a href="torchrec.models.html#module-torchrec.models.dlrm">torchrec.models.dlrm</a>
</li>
        <li><a href="torchrec.modules.html#module-0">torchrec.modules</a>, <a href="torchrec.modules.html#module-torchrec.modules">[1]</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.activation">torchrec.modules.activation</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.crossnet">torchrec.modules.crossnet</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.deepfm">torchrec.modules.deepfm</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.embedding_configs">torchrec.modules.embedding_configs</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.embedding_modules">torchrec.modules.embedding_modules</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.feature_processor">torchrec.modules.feature_processor</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.lazy_extension">torchrec.modules.lazy_extension</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.mlp">torchrec.modules.mlp</a>
</li>
        <li><a href="torchrec.modules.html#module-torchrec.modules.utils">torchrec.modules.utils</a>
</li>
        <li><a href="torchrec.optim.html#module-0">torchrec.optim</a>, <a href="torchrec.optim.html#module-torchrec.optim">[1]</a>
</li>
        <li><a href="torchrec.optim.html#module-torchrec.optim.clipping">torchrec.optim.clipping</a>
</li>
        <li><a href="torchrec.optim.html#module-torchrec.optim.fused">torchrec.optim.fused</a>
</li>
        <li><a href="torchrec.optim.html#module-torchrec.optim.keyed">torchrec.optim.keyed</a>
</li>
        <li><a href="torchrec.optim.html#module-torchrec.optim.warmup">torchrec.optim.warmup</a>
</li>
        <li><a href="torchrec.quant.html#module-0">torchrec.quant</a>, <a href="torchrec.quant.html#module-torchrec.quant">[1]</a>
</li>
        <li><a href="torchrec.quant.html#module-torchrec.quant.embedding_modules">torchrec.quant.embedding_modules</a>
</li>
        <li><a href="torchrec.sparse.html#module-0">torchrec.sparse</a>, <a href="torchrec.sparse.html#module-torchrec.sparse">[1]</a>
</li>
        <li><a href="torchrec.sparse.html#module-torchrec.sparse.jagged_tensor">torchrec.sparse.jagged_tensor</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.module">module (torchrec.distributed.model_parallel.DistributedModelParallel property)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.module">(torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineContext.module_contexts">module_contexts (torchrec.distributed.train_pipeline.TrainPipelineContext attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.Tracer.module_stack">module_stack (torchrec.distributed.train_pipeline.Tracer attribute)</a>

      <ul>
        <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.module_stack">(torchrec.fx.tracer.Tracer attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionSharder.module_type">module_type (torchrec.distributed.embedding.EmbeddingCollectionSharder property)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder.module_type">(torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagSharder.module_type">(torchrec.distributed.embeddingbag.EmbeddingBagSharder property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.QuantEmbeddingBagCollectionSharder.module_type">(torchrec.distributed.quant_embeddingbag.QuantEmbeddingBagCollectionSharder property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder.module_type">(torchrec.distributed.types.ModuleSharder property)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder">ModuleSharder (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ModuleShardingMixIn">ModuleShardingMixIn (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleShardingPlan">ModuleShardingPlan (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.movielens.movielens_20m">movielens_20m() (in module torchrec.datasets.movielens)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.movielens.movielens_25m">movielens_25m() (in module torchrec.datasets.movielens)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#id26">name (torchrec.distributed.train_pipeline.ArgInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.ArgInfo.name">[1]</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.PipelinedForward.name">(torchrec.distributed.train_pipeline.PipelinedForward property)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.name">(torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup.named_buffers">named_buffers() (torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup.named_buffers">(torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedLookupMixin.named_buffers">(torchrec.distributed.embedding_lookup.InferGroupedLookupMixin method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup.named_buffers">(torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup.named_buffers">(torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.named_buffers">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule.named_buffers">(torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.named_buffers">(torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedProcessor.named_buffers">(torchrec.modules.feature_processor.PositionWeightedProcessor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.named_modules">named_modules() (torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup.named_parameters">named_parameters() (torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup.named_parameters">(torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedLookupMixin.named_parameters">(torchrec.distributed.embedding_lookup.InferGroupedLookupMixin method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup.named_parameters">(torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup.named_parameters">(torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.named_parameters">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule.named_parameters">(torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.named_parameters">(torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup.named_parameters_by_table">named_parameters_by_table() (torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup.named_parameters_by_table">(torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection.need_indices">need_indices() (torchrec.modules.embedding_modules.EmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollectionInterface.need_indices">(torchrec.modules.embedding_modules.EmbeddingCollectionInterface method)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.need_indices">(torchrec.quant.embedding_modules.EmbeddingCollection method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.need_pos">need_pos (torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.QualNameMetadata.need_preproc">need_preproc (torchrec.inference.modules.QualNameMetadata attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.Tracer.node_name_to_scope">node_name_to_scope (torchrec.distributed.train_pipeline.Tracer attribute)</a>

      <ul>
        <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.node_name_to_scope">(torchrec.fx.tracer.Tracer attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.PoolingType.NONE">NONE (torchrec.modules.embedding_configs.PoolingType attribute)</a>

      <ul>
        <li><a href="torchrec.optim.html#torchrec.optim.clipping.GradientClipping.NONE">(torchrec.optim.clipping.GradientClipping attribute)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupPolicy.NONE">(torchrec.optim.warmup.WarmupPolicy attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.none_throws">none_throws() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.perf_models.NoopPerfModel">NoopPerfModel (class in torchrec.distributed.planner.perf_models)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NoOpQuantizedCommCodec">NoOpQuantizedCommCodec (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.clipping.GradientClipping.NORM">NORM (torchrec.optim.clipping.GradientClipping attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NoWait">NoWait (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NullShardedModuleContext">NullShardedModuleContext (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NullShardingContext">NullShardingContext (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.num_embeddings">num_embeddings (torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingConfig.num_embeddings">(torchrec.modules.embedding_configs.EmbeddingConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.num_features">num_features() (torchrec.distributed.embedding_types.GroupedEmbeddingConfig method)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.num_features">(torchrec.modules.embedding_configs.BaseEmbeddingConfig method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.num_inputs">num_inputs (torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints.num_poolings">num_poolings (torchrec.distributed.planner.types.ParameterConstraints attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.num_shards">num_shards (torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="O">O</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Shard.offset">offset (torchrec.distributed.planner.types.Shard attribute)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key">offset_per_key() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.offset_per_key">(torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offset_per_key_or_none">offset_per_key_or_none() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.offsets">offsets() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.offsets_or_none">offsets_or_none() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.offsets_or_none">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.optimizer_type_to_emb_opt_type">optimizer_type_to_emb_opt_type() (in module torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.optimizers">optimizers (torchrec.optim.keyed.CombinedOptimizer property)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper">OptimizerWrapper (class in torchrec.optim.keyed)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType">OptimType (class in torchrec.distributed.embedding_types)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PlannerErrorType.OTHER">OTHER (torchrec.distributed.planner.types.PlannerErrorType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection.output_dist">output_dist() (torchrec.distributed.embedding.ShardedEmbeddingCollection method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.output_dist">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection.output_dist">(torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.output_dist">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.output_dist">(torchrec.distributed.types.ShardedModule method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection.output_dtype">output_dtype() (torchrec.quant.embedding_modules.EmbeddingBagCollection method)</a>

      <ul>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.output_dtype">(torchrec.quant.embedding_modules.EmbeddingCollection method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id17">output_split_sizes (torchrec.distributed.comm_ops.All2AllVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllVInfo.output_split_sizes">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllDenseInfo.output_splits">output_splits (torchrec.distributed.comm_ops.All2AllDenseInfo attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.html#id9">(torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.output_splits">[1]</a>
</li>
      </ul></li>
      <li><a href="torchrec.models.html#torchrec.models.deepfm.OverArch">OverArch (class in torchrec.models.deepfm)</a>

      <ul>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.OverArch">(class in torchrec.models.dlrm)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="P">P</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.ParallelReadConcat">ParallelReadConcat (class in torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingInfo.param">param (torchrec.distributed.embedding_sharding.EmbeddingShardingInfo attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.param_groups">param_groups (torchrec.optim.keyed.CombinedOptimizer property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingInfo.param_sharding">param_sharding (torchrec.distributed.embedding_sharding.EmbeddingShardingInfo attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints">ParameterConstraints (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterSharding">ParameterSharding (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterStorage">ParameterStorage (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.params">params (torchrec.optim.keyed.CombinedOptimizer property)</a>
</li>
      <li><a href="torchrec.datasets.scripts.html#torchrec.datasets.scripts.contiguous_preproc_criteo.parse_args">parse_args() (in module torchrec.datasets.scripts.contiguous_preproc_criteo)</a>

      <ul>
        <li><a href="torchrec.datasets.scripts.html#torchrec.datasets.scripts.npy_preproc_criteo.parse_args">(in module torchrec.datasets.scripts.npy_preproc_criteo)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.PARTIAL_ROWWISE_ADAM">PARTIAL_ROWWISE_ADAM (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.PARTIAL_ROWWISE_LAMB">PARTIAL_ROWWISE_LAMB (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PlannerErrorType.PARTITION">PARTITION (torchrec.distributed.planner.types.PlannerErrorType attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.partitioners.GreedyPerfPartitioner.partition">partition() (torchrec.distributed.planner.partitioners.GreedyPerfPartitioner method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Partitioner.partition">(torchrec.distributed.planner.types.Partitioner method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PartitionByType">PartitionByType (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Partitioner">Partitioner (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.path">path (torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
      <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.path_of_module">path_of_module() (torchrec.fx.tracer.Tracer method)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.mlp.Perceptron">Perceptron (class in torchrec.modules.mlp)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.DeviceHardware.perf">perf (torchrec.distributed.planner.types.DeviceHardware attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Shard.perf">(torchrec.distributed.planner.types.Shard attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.shard_estimators.perf_func_emb_wall_time">perf_func_emb_wall_time() (in module torchrec.distributed.planner.shard_estimators)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PerfModel">PerfModel (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.permute">permute() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.distributed.html#id10">permuted_lengths_after_sparse_data_all2all (torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.permuted_lengths_after_sparse_data_all2all">[1]</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Batch.pin_memory">pin_memory() (torchrec.datasets.utils.Batch method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.pin_memory">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.BatchingMetadata.pinned">pinned (torchrec.inference.modules.BatchingMetadata attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.PipelinedForward">PipelinedForward (class in torchrec.distributed.train_pipeline)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.utils.placement">placement() (in module torchrec.distributed.planner.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.plan">plan (torchrec.distributed.model_parallel.DistributedModelParallel property)</a>

      <ul>
        <li><a href="torchrec.distributed.html#id27">(torchrec.distributed.types.ShardingPlan attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.types.ShardingPlan.plan">[1]</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.planners.EmbeddingShardingPlanner.plan">plan() (torchrec.distributed.planner.planners.EmbeddingShardingPlanner method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingPlanner.plan">(torchrec.distributed.types.ShardingPlanner method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PlannerError">PlannerError</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PlannerErrorType">PlannerErrorType (class in torchrec.distributed.planner.types)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupStage.policy">policy (torchrec.optim.warmup.WarmupStage attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupPolicy.POLY">POLY (torchrec.optim.warmup.WarmupPolicy attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.CommOp.POOLED_EMBEDDINGS_ALL_TO_ALL">POOLED_EMBEDDINGS_ALL_TO_ALL (torchrec.distributed.types.CommOp attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.CommOp.POOLED_EMBEDDINGS_REDUCE_SCATTER">POOLED_EMBEDDINGS_REDUCE_SCATTER (torchrec.distributed.types.CommOp attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAllGather">PooledEmbeddingsAllGather (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAllGather">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll">PooledEmbeddingsAllToAll (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAwaitable">PooledEmbeddingsAwaitable (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAwaitable">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter">PooledEmbeddingsReduceScatter (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.GroupedEmbeddingConfig.pooling">pooling (torchrec.distributed.embedding_types.GroupedEmbeddingConfig attribute)</a>

      <ul>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingBagConfig.pooling">(torchrec.modules.embedding_configs.EmbeddingBagConfig attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.EmbeddingTableConfig.pooling">(torchrec.modules.embedding_configs.EmbeddingTableConfig attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints.pooling_factors">pooling_factors (torchrec.distributed.planner.types.ParameterConstraints attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.pooling_type_to_pooling_mode">pooling_type_to_pooling_mode() (in module torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.pooling_type_to_str">pooling_type_to_str() (in module torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.PoolingType">PoolingType (class in torchrec.modules.embedding_configs)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedModule">PositionWeightedModule (class in torchrec.modules.feature_processor)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedProcessor">PositionWeightedProcessor (class in torchrec.modules.feature_processor)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.post_load_state_dict">post_load_state_dict() (torchrec.optim.keyed.CombinedOptimizer method)</a>

      <ul>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizer.post_load_state_dict">(torchrec.optim.keyed.KeyedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper.post_load_state_dict">(torchrec.optim.keyed.OptimizerWrapper method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupOptimizer.post_load_state_dict">(torchrec.optim.warmup.WarmupOptimizer method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictModule.predict_forward">predict_forward() (torchrec.inference.modules.PredictModule method)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictModule.predict_module">predict_module (torchrec.inference.modules.PredictModule property)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory">PredictFactory (class in torchrec.inference.modules)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.model_packager.PredictFactoryPackager">PredictFactoryPackager (class in torchrec.inference.model_packager)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictModule">PredictModule (class in torchrec.inference.modules)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.prepend_opt_key">prepend_opt_key() (torchrec.optim.keyed.CombinedOptimizer static method)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.utils.prod">prod() (in module torchrec.distributed.planner.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipeline.progress">progress() (torchrec.distributed.train_pipeline.TrainPipeline method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineBase.progress">(torchrec.distributed.train_pipeline.TrainPipelineBase method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineSparseDist.progress">(torchrec.distributed.train_pipeline.TrainPipelineSparseDist method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GreedyProposer.propose">propose() (torchrec.distributed.planner.proposers.GreedyProposer method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.GridSearchProposer.propose">(torchrec.distributed.planner.proposers.GridSearchProposer method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.UniformProposer.propose">(torchrec.distributed.planner.proposers.UniformProposer method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Proposer.propose">(torchrec.distributed.planner.types.Proposer method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Proposer">Proposer (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.proposers_to_proposals_list">proposers_to_proposals_list() (in module torchrec.distributed.planner.proposers)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.Tracer.proxy_buffer_attributes">proxy_buffer_attributes (torchrec.distributed.train_pipeline.Tracer attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="Q">Q</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingSharding.qcomm_codecs_registry">qcomm_codecs_registry (torchrec.distributed.embedding_sharding.EmbeddingSharding property)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder.qcomm_codecs_registry">(torchrec.distributed.types.ModuleSharder property)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.qcomm_codecs_registry">(torchrec.distributed.types.ShardedModule property)</a>
</li>
      </ul></li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.qualname_metadata">qualname_metadata() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.qualname_metadata_json">qualname_metadata_json() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.QualNameMetadata">QualNameMetadata (class in torchrec.inference.modules)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel.QUANT">QUANT (torchrec.distributed.embedding_types.EmbeddingComputeKernel attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel.QUANT_UVM">QUANT_UVM (torchrec.distributed.embedding_types.EmbeddingComputeKernel attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.EmbeddingComputeKernel.QUANT_UVM_CACHING">QUANT_UVM_CACHING (torchrec.distributed.embedding_types.EmbeddingComputeKernel attribute)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.QuantEmbeddingBagCollectionSharder">QuantEmbeddingBagCollectionSharder (class in torchrec.distributed.quant_embeddingbag)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.quantize_dense">quantize_dense() (in module torchrec.inference.modules)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.quantize_embeddings">quantize_embeddings() (in module torchrec.inference.modules)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.quantize_feature">quantize_feature() (in module torchrec.inference.modules)</a>
</li>
      <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.quantize_state_dict">quantize_state_dict() (in module torchrec.quant.embedding_modules)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.NoOpQuantizedCommCodec.quantized_dtype">quantized_dtype() (torchrec.distributed.types.NoOpQuantizedCommCodec method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodec.quantized_dtype">(torchrec.distributed.types.QuantizedCommCodec method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodec">QuantizedCommCodec (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.QuantizedCommCodecs">QuantizedCommCodecs (class in torchrec.distributed.types)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.rand_split_train_val">rand_split_train_val() (in module torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.random.RandomRecDataset">RandomRecDataset (class in torchrec.datasets.random)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.DeviceHardware.rank">rank (torchrec.distributed.planner.types.DeviceHardware attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Shard.rank">(torchrec.distributed.planner.types.Shard attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterSharding.ranks">ranks (torchrec.distributed.types.ParameterSharding attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.perf_models.NoopPerfModel.rate">rate() (torchrec.distributed.planner.perf_models.NoopPerfModel method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PerfModel.rate">(torchrec.distributed.planner.types.PerfModel method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.ReadLinesFromCSV">ReadLinesFromCSV (class in torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Batch.record_stream">record_stream() (torchrec.datasets.utils.Batch method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionContext.record_stream">(torchrec.distributed.embedding.EmbeddingCollectionContext method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.EmbeddingShardingContext.record_stream">(torchrec.distributed.embedding_sharding.EmbeddingShardingContext method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.KJTList.record_stream">(torchrec.distributed.embedding_types.KJTList method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ListOfKJTList.record_stream">(torchrec.distributed.embedding_types.ListOfKJTList method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionContext.record_stream">(torchrec.distributed.embeddingbag.EmbeddingBagCollectionContext method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.NullShardedModuleContext.record_stream">(torchrec.distributed.types.NullShardedModuleContext method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.NullShardingContext.record_stream">(torchrec.distributed.types.NullShardingContext method)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.record_stream">(torchrec.sparse.jagged_tensor.JaggedTensor method)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.record_stream">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.record_stream">(torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.reduce_scatter_base_pooled">reduce_scatter_base_pooled() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.reduce_scatter_pooled">reduce_scatter_pooled() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.reduce_scatter_v_pooled">reduce_scatter_v_pooled() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatter_Req">ReduceScatter_Req (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatter_Wait">ReduceScatter_Wait (class in torchrec.distributed.comm_ops)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBase_Req">ReduceScatterBase_Req (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBase_Wait">ReduceScatterBase_Wait (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterBaseInfo">ReduceScatterBaseInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterInfo">ReduceScatterInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterV_Req">ReduceScatterV_Req (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterV_Wait">ReduceScatterV_Wait (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterVInfo">ReduceScatterVInfo (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.regroup">regroup() (torchrec.sparse.jagged_tensor.KeyedTensor static method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.regroup_as_dict">regroup_as_dict() (torchrec.sparse.jagged_tensor.KeyedTensor static method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.replace_placement_with_meta_device">replace_placement_with_meta_device() (in module torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.Request">Request (class in torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.storage_reservations.FixedPercentageStorageReservation.reserve">reserve() (torchrec.distributed.planner.storage_reservations.FixedPercentageStorageReservation method)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.storage_reservations.HeuristicalStorageReservation.reserve">(torchrec.distributed.planner.storage_reservations.HeuristicalStorageReservation method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.storage_reservations.InferenceStorageReservation.reserve">(torchrec.distributed.planner.storage_reservations.InferenceStorageReservation method)</a>
</li>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.StorageReservation.reserve">(torchrec.distributed.planner.types.StorageReservation method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.result_metadata">result_metadata() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingType.ROW_WISE">ROW_WISE (torchrec.distributed.types.ShardingType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.ROWWISE_ADAGRAD">ROWWISE_ADAGRAD (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.collective_utils.run_on_leader">run_on_leader() (in module torchrec.distributed.collective_utils)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.run_weights_dependent_transformations">run_weights_dependent_transformations() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictFactory.run_weights_independent_tranformations">run_weights_independent_tranformations() (torchrec.inference.modules.PredictFactory method)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingDist">RwPooledEmbeddingDist (class in torchrec.distributed.sharding.rw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingSharding">RwPooledEmbeddingSharding (class in torchrec.distributed.sharding.rw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwSparseFeaturesDist">RwSparseFeaturesDist (class in torchrec.distributed.sharding.rw_sharding)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.safe_cast">safe_cast() (in module torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.save_param_groups">save_param_groups() (torchrec.optim.keyed.CombinedOptimizer method)</a>

      <ul>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizer.save_param_groups">(torchrec.optim.keyed.KeyedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper.save_param_groups">(torchrec.optim.keyed.OptimizerWrapper method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.inference.html#torchrec.inference.model_packager.PredictFactoryPackager.save_predict_factory">save_predict_factory() (torchrec.inference.model_packager.PredictFactoryPackager class method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.Tracer.scope">scope (torchrec.distributed.train_pipeline.Tracer attribute)</a>

      <ul>
        <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.scope">(torchrec.fx.tracer.Tracer attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.scope">scope() (in module torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SeqEmbeddingsAllToOne">SeqEmbeddingsAllToOne (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SeqEmbeddingsAllToOne">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.CommOp.SEQUENCE_EMBEDDINGS_ALL_TO_ALL">SEQUENCE_EMBEDDINGS_ALL_TO_ALL (torchrec.distributed.types.CommOp attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll">SequenceEmbeddingsAllToAll (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll">[1]</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SequenceEmbeddingsAwaitable">SequenceEmbeddingsAwaitable (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SequenceEmbeddingsAwaitable">[1]</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.model_packager.PredictFactoryPackager.set_extern_modules">set_extern_modules() (torchrec.inference.model_packager.PredictFactoryPackager class method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.comm_ops.set_gradient_division">set_gradient_division() (in module torchrec.distributed.comm_ops)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.model_packager.PredictFactoryPackager.set_mocked_modules">set_mocked_modules() (torchrec.inference.model_packager.PredictFactoryPackager class method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.SGD">SGD (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.OptimType.SHAMPOO">SHAMPOO (torchrec.distributed.embedding_types.OptimType attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Shard">Shard (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionSharder.shard">shard() (torchrec.distributed.embedding.EmbeddingCollectionSharder method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder.shard">(torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagSharder.shard">(torchrec.distributed.embeddingbag.EmbeddingBagSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.QuantEmbeddingBagCollectionSharder.shard">(torchrec.distributed.quant_embeddingbag.QuantEmbeddingBagCollectionSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder.shard">(torchrec.distributed.types.ModuleSharder class method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardableModule.shard">(torchrec.distributed.types.ShardableModule method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionSharder.shardable_parameters">shardable_parameters() (torchrec.distributed.embedding.EmbeddingCollectionSharder method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder.shardable_parameters">(torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder.shardable_parameters">(torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagSharder.shardable_parameters">(torchrec.distributed.embeddingbag.EmbeddingBagSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder.shardable_parameters">(torchrec.distributed.types.ModuleSharder method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardableModule">ShardableModule (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.utils.sharded_model_copy">sharded_model_copy (class in torchrec.distributed.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.sharded_parameter_names">sharded_parameter_names() (torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.sharded_parameter_names">(torchrec.distributed.types.ShardedModule method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedConfig">ShardedConfig (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag">ShardedEmbeddingBag (class in torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection">ShardedEmbeddingBagCollection (class in torchrec.distributed.embeddingbag)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection">ShardedEmbeddingCollection (class in torchrec.distributed.embedding)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedEmbeddingModule">ShardedEmbeddingModule (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedEmbeddingTable">ShardedEmbeddingTable (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedMetaConfig">ShardedMetaConfig (class in torchrec.distributed.embedding_types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule">ShardedModule (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection">ShardedQuantEmbeddingBagCollection (class in torchrec.distributed.quant_embeddingbag)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.utils.sharder_name">sharder_name() (in module torchrec.distributed.planner.utils)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardEstimator">ShardEstimator (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionContext.sharding_contexts">sharding_contexts (torchrec.distributed.embedding.EmbeddingCollectionContext attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.EmbeddingBagCollectionContext.sharding_contexts">(torchrec.distributed.embeddingbag.EmbeddingBagCollectionContext attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.partitioners.ShardingOptionGroup.sharding_options">sharding_options (torchrec.distributed.planner.partitioners.ShardingOptionGroup attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterSharding.sharding_spec">sharding_spec (torchrec.distributed.types.ParameterSharding attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ParameterSharding.sharding_type">sharding_type (torchrec.distributed.types.ParameterSharding attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ParameterConstraints.sharding_types">sharding_types (torchrec.distributed.planner.types.ParameterConstraints attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.EmbeddingCollectionSharder.sharding_types">sharding_types() (torchrec.distributed.embedding.EmbeddingCollectionSharder method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingSharder.sharding_types">(torchrec.distributed.embedding_types.BaseEmbeddingSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder.sharding_types">(torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder.sharding_types">(torchrec.distributed.types.ModuleSharder method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingEnv">ShardingEnv (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption">ShardingOption (class in torchrec.distributed.planner.types)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.partitioners.ShardingOptionGroup">ShardingOptionGroup (class in torchrec.distributed.planner.partitioners)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingPlan">ShardingPlan (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingPlanner">ShardingPlanner (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ModuleShardingMixIn.shardings">shardings (torchrec.distributed.embedding_types.ModuleShardingMixIn property)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.shardings">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection property)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingType">ShardingType (class in torchrec.distributed.types)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.BinaryCriteoUtils.shuffle">shuffle() (torchrec.datasets.criteo.BinaryCriteoUtils static method)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.deepfm.SimpleDeepFMNN">SimpleDeepFMNN (class in torchrec.models.deepfm)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Shard.size">size (torchrec.distributed.planner.types.Shard attribute)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM_DCN.sparse_arch">sparse_arch (torchrec.models.dlrm.DLRM_DCN attribute)</a>

      <ul>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM_Projection.sparse_arch">(torchrec.models.dlrm.DLRM_Projection attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.models.html#torchrec.models.dlrm.SparseArch.sparse_feature_names">sparse_feature_names (torchrec.models.dlrm.SparseArch property)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Batch.sparse_features">sparse_features (torchrec.datasets.utils.Batch attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.sparse_grad_parameter_names">sparse_grad_parameter_names() (torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.BinaryCriteoUtils.sparse_to_contiguous">sparse_to_contiguous() (torchrec.datasets.criteo.BinaryCriteoUtils static method)</a>
</li>
      <li><a href="torchrec.models.html#torchrec.models.deepfm.SparseArch">SparseArch (class in torchrec.models.deepfm)</a>

      <ul>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.SparseArch">(class in torchrec.models.dlrm)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.split">split() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SplitsAllToAllAwaitable">SplitsAllToAllAwaitable (class in torchrec.distributed.dist_data)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SplitsAllToAllAwaitable">[1]</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.state">state (torchrec.optim.keyed.CombinedOptimizer property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup.state_dict">state_dict() (torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup.state_dict">(torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedLookupMixin.state_dict">(torchrec.distributed.embedding_lookup.InferGroupedLookupMixin method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup.state_dict">(torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup.state_dict">(torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.state_dict">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule.state_dict">(torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.state_dict">(torchrec.distributed.model_parallel.DistributedModelParallel method)</a>
</li>
        <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictModule.state_dict">(torchrec.inference.modules.PredictModule method)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedProcessor.state_dict">(torchrec.modules.feature_processor.PositionWeightedProcessor method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizer.state_dict">(torchrec.optim.keyed.KeyedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper.state_dict">(torchrec.optim.keyed.OptimizerWrapper method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Stats">Stats (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupPolicy.STEP">STEP (torchrec.optim.warmup.WarmupPolicy attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.clipping.GradientClippingOptimizer.step">step() (torchrec.optim.clipping.GradientClippingOptimizer method)</a>

      <ul>
        <li><a href="torchrec.optim.html#torchrec.optim.fused.EmptyFusedOptimizer.step">(torchrec.optim.fused.EmptyFusedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.fused.FusedOptimizer.step">(torchrec.optim.fused.FusedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.step">(torchrec.optim.keyed.CombinedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizerWrapper.step">(torchrec.optim.keyed.KeyedOptimizerWrapper method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper.step">(torchrec.optim.keyed.OptimizerWrapper method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupOptimizer.step">(torchrec.optim.warmup.WarmupOptimizer method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Storage">Storage (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.DeviceHardware.storage">storage (torchrec.distributed.planner.types.DeviceHardware attribute)</a>

      <ul>
        <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Shard.storage">(torchrec.distributed.planner.types.Shard attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.partitioners.ShardingOptionGroup.storage_sum">storage_sum (torchrec.distributed.planner.partitioners.ShardingOptionGroup attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingSharder.storage_usage">storage_usage() (torchrec.distributed.embedding_types.BaseEmbeddingSharder method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder.storage_usage">(torchrec.distributed.embedding_types.BaseQuantEmbeddingSharder method)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ModuleSharder.storage_usage">(torchrec.distributed.types.ModuleSharder method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.StorageReservation">StorageReservation (class in torchrec.distributed.planner.types)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PlannerErrorType.STRICT_CONSTRAINTS">STRICT_CONSTRAINTS (torchrec.distributed.planner.types.PlannerErrorType attribute)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.stride">stride() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.PoolingType.SUM">SUM (torchrec.modules.embedding_configs.PoolingType attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.activation.SwishLayerNorm">SwishLayerNorm (class in torchrec.modules.activation)</a>
</li>
      <li><a href="torchrec.fx.html#torchrec.fx.tracer.symbolic_trace">symbolic_trace() (in module torchrec.fx.tracer)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.sync">sync() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineSparseDist.synced_pipeline_id">synced_pipeline_id (torchrec.distributed.train_pipeline.TrainPipelineSparseDist attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingType.TABLE_COLUMN_WISE">TABLE_COLUMN_WISE (torchrec.distributed.types.ShardingType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingType.TABLE_ROW_WISE">TABLE_ROW_WISE (torchrec.distributed.types.ShardingType attribute)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardingType.TABLE_WISE">TABLE_WISE (torchrec.distributed.types.ShardingType attribute)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.tensor">tensor (torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.Batch.to">to() (torchrec.datasets.utils.Batch method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.to">(torchrec.sparse.jagged_tensor.JaggedTensor method)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.to">(torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.to_dense">to_dense() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.to_dict">to_dict() (torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.to_dict">(torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.to_padded_dense">to_padded_dense() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology">Topology (class in torchrec.distributed.planner.types)</a>
</li>
      <li>
    torchrec.datasets

      <ul>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets">module</a>
</li>
      </ul></li>
      <li>
    torchrec.datasets.criteo

      <ul>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.criteo">module</a>
</li>
      </ul></li>
      <li>
    torchrec.datasets.movielens

      <ul>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.movielens">module</a>
</li>
      </ul></li>
      <li>
    torchrec.datasets.random

      <ul>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.random">module</a>
</li>
      </ul></li>
      <li>
    torchrec.datasets.scripts

      <ul>
        <li><a href="torchrec.datasets.scripts.html#module-torchrec.datasets.scripts">module</a>
</li>
      </ul></li>
      <li>
    torchrec.datasets.scripts.contiguous_preproc_criteo

      <ul>
        <li><a href="torchrec.datasets.scripts.html#module-torchrec.datasets.scripts.contiguous_preproc_criteo">module</a>
</li>
      </ul></li>
      <li>
    torchrec.datasets.scripts.npy_preproc_criteo

      <ul>
        <li><a href="torchrec.datasets.scripts.html#module-torchrec.datasets.scripts.npy_preproc_criteo">module</a>
</li>
      </ul></li>
      <li>
    torchrec.datasets.utils

      <ul>
        <li><a href="torchrec.datasets.html#module-torchrec.datasets.utils">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.collective_utils

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.collective_utils">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.comm

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.comm">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.comm_ops

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.comm_ops">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.dist_data

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.dist_data">module</a>, <a href="torchrec.distributed.sharding.html#module-torchrec.distributed.dist_data">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.embedding

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.embedding_lookup

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding_lookup">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.embedding_sharding

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding_sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.embedding_types

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embedding_types">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.embeddingbag

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.embeddingbag">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.grouped_position_weighted

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.grouped_position_weighted">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.model_parallel

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.model_parallel">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.constants

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.constants">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.enumerators

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.enumerators">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.partitioners

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.partitioners">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.perf_models

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.perf_models">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.planners

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.planners">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.proposers

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.proposers">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.shard_estimators

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.shard_estimators">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.stats

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.stats">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.storage_reservations

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.storage_reservations">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.types

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.types">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.planner.utils

      <ul>
        <li><a href="torchrec.distributed.planner.html#module-torchrec.distributed.planner.utils">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.quant_embeddingbag

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.quant_embeddingbag">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.sharding

      <ul>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.sharding.cw_sharding

      <ul>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.cw_sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.sharding.dp_sharding

      <ul>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.dp_sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.sharding.rw_sharding

      <ul>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.rw_sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.sharding.tw_sharding

      <ul>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.tw_sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.sharding.twcw_sharding

      <ul>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.twcw_sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.sharding.twrw_sharding

      <ul>
        <li><a href="torchrec.distributed.sharding.html#module-torchrec.distributed.sharding.twrw_sharding">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.train_pipeline

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.train_pipeline">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.types

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.types">module</a>
</li>
      </ul></li>
      <li>
    torchrec.distributed.utils

      <ul>
        <li><a href="torchrec.distributed.html#module-torchrec.distributed.utils">module</a>
</li>
      </ul></li>
      <li>
    torchrec.fx

      <ul>
        <li><a href="torchrec.fx.html#module-0">module</a>, <a href="torchrec.fx.html#module-torchrec.fx">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.fx.tracer

      <ul>
        <li><a href="torchrec.fx.html#module-torchrec.fx.tracer">module</a>
</li>
      </ul></li>
      <li>
    torchrec.inference

      <ul>
        <li><a href="torchrec.inference.html#module-0">module</a>, <a href="torchrec.inference.html#module-torchrec.inference">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.inference.model_packager

      <ul>
        <li><a href="torchrec.inference.html#module-torchrec.inference.model_packager">module</a>
</li>
      </ul></li>
      <li>
    torchrec.inference.modules

      <ul>
        <li><a href="torchrec.inference.html#module-torchrec.inference.modules">module</a>
</li>
      </ul></li>
      <li>
    torchrec.models

      <ul>
        <li><a href="torchrec.models.html#module-0">module</a>, <a href="torchrec.models.html#module-torchrec.models">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.models.deepfm

      <ul>
        <li><a href="torchrec.models.html#module-torchrec.models.deepfm">module</a>
</li>
      </ul></li>
      <li>
    torchrec.models.dlrm

      <ul>
        <li><a href="torchrec.models.html#module-torchrec.models.dlrm">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules

      <ul>
        <li><a href="torchrec.modules.html#module-0">module</a>, <a href="torchrec.modules.html#module-torchrec.modules">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.activation

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.activation">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.crossnet

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.crossnet">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.deepfm

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.deepfm">module</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    torchrec.modules.embedding_configs

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.embedding_configs">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.embedding_modules

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.embedding_modules">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.feature_processor

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.feature_processor">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.lazy_extension

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.lazy_extension">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.mlp

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.mlp">module</a>
</li>
      </ul></li>
      <li>
    torchrec.modules.utils

      <ul>
        <li><a href="torchrec.modules.html#module-torchrec.modules.utils">module</a>
</li>
      </ul></li>
      <li>
    torchrec.optim

      <ul>
        <li><a href="torchrec.optim.html#module-0">module</a>, <a href="torchrec.optim.html#module-torchrec.optim">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.optim.clipping

      <ul>
        <li><a href="torchrec.optim.html#module-torchrec.optim.clipping">module</a>
</li>
      </ul></li>
      <li>
    torchrec.optim.fused

      <ul>
        <li><a href="torchrec.optim.html#module-torchrec.optim.fused">module</a>
</li>
      </ul></li>
      <li>
    torchrec.optim.keyed

      <ul>
        <li><a href="torchrec.optim.html#module-torchrec.optim.keyed">module</a>
</li>
      </ul></li>
      <li>
    torchrec.optim.warmup

      <ul>
        <li><a href="torchrec.optim.html#module-torchrec.optim.warmup">module</a>
</li>
      </ul></li>
      <li>
    torchrec.quant

      <ul>
        <li><a href="torchrec.quant.html#module-0">module</a>, <a href="torchrec.quant.html#module-torchrec.quant">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.quant.embedding_modules

      <ul>
        <li><a href="torchrec.quant.html#module-torchrec.quant.embedding_modules">module</a>
</li>
      </ul></li>
      <li>
    torchrec.sparse

      <ul>
        <li><a href="torchrec.sparse.html#module-0">module</a>, <a href="torchrec.sparse.html#module-torchrec.sparse">[1]</a>
</li>
      </ul></li>
      <li>
    torchrec.sparse.jagged_tensor

      <ul>
        <li><a href="torchrec.sparse.html#module-torchrec.sparse.jagged_tensor">module</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#id23">total_input_size (torchrec.distributed.comm_ops.ReduceScatterVInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.ReduceScatterVInfo.total_input_size">[1]</a>
</li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.ShardingOption.total_storage">total_storage (torchrec.distributed.planner.types.ShardingOption property)</a>
</li>
      <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer.trace">trace() (torchrec.fx.tracer.Tracer method)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.Tracer">Tracer (class in torchrec.distributed.train_pipeline)</a>

      <ul>
        <li><a href="torchrec.fx.html#torchrec.fx.tracer.Tracer">(class in torchrec.fx.tracer)</a>
</li>
      </ul></li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.train_filter">train_filter() (in module torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.EmbeddingsAllToOne.training">training (torchrec.distributed.dist_data.EmbeddingsAllToOne attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.EmbeddingsAllToOne.training">[1]</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTAllToAll.training">(torchrec.distributed.dist_data.KJTAllToAll attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTAllToAll.training">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.KJTOneToAll.training">(torchrec.distributed.dist_data.KJTOneToAll attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.KJTOneToAll.training">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAllGather.training">(torchrec.distributed.dist_data.PooledEmbeddingsAllGather attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAllGather.training">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll.training">(torchrec.distributed.dist_data.PooledEmbeddingsAllToAll attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsAllToAll.training">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter.training">(torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.PooledEmbeddingsReduceScatter.training">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SeqEmbeddingsAllToOne.training">(torchrec.distributed.dist_data.SeqEmbeddingsAllToOne attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SeqEmbeddingsAllToOne.training">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll.training">(torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll attribute)</a>, <a href="torchrec.distributed.sharding.html#torchrec.distributed.dist_data.SequenceEmbeddingsAllToAll.training">[1]</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding.ShardedEmbeddingCollection.training">(torchrec.distributed.embedding.ShardedEmbeddingCollection attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup.training">(torchrec.distributed.embedding_lookup.GroupedEmbeddingsLookup attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup.training">(torchrec.distributed.embedding_lookup.GroupedPooledEmbeddingsLookup attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedEmbeddingsLookup.training">(torchrec.distributed.embedding_lookup.InferGroupedEmbeddingsLookup attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.InferGroupedPooledEmbeddingsLookup.training">(torchrec.distributed.embedding_lookup.InferGroupedPooledEmbeddingsLookup attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup.training">(torchrec.distributed.embedding_lookup.MetaInferGroupedEmbeddingsLookup attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup.training">(torchrec.distributed.embedding_lookup.MetaInferGroupedPooledEmbeddingsLookup attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.BaseEmbeddingDist.training">(torchrec.distributed.embedding_sharding.BaseEmbeddingDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_sharding.BaseSparseFeaturesDist.training">(torchrec.distributed.embedding_sharding.BaseSparseFeaturesDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseEmbeddingLookup.training">(torchrec.distributed.embedding_types.BaseEmbeddingLookup attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.BaseGroupedFeatureProcessor.training">(torchrec.distributed.embedding_types.BaseGroupedFeatureProcessor attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embedding_types.ShardedEmbeddingModule.training">(torchrec.distributed.embedding_types.ShardedEmbeddingModule attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBag.training">(torchrec.distributed.embeddingbag.ShardedEmbeddingBag attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection.training">(torchrec.distributed.embeddingbag.ShardedEmbeddingBagCollection attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule.training">(torchrec.distributed.grouped_position_weighted.GroupedPositionWeightedModule attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DistributedModelParallel.training">(torchrec.distributed.model_parallel.DistributedModelParallel attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection.training">(torchrec.distributed.quant_embeddingbag.ShardedQuantEmbeddingBagCollection attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingDist.training">(torchrec.distributed.sharding.dp_sharding.DpPooledEmbeddingDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.dp_sharding.DpSparseFeaturesDist.training">(torchrec.distributed.sharding.dp_sharding.DpSparseFeaturesDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingDist.training">(torchrec.distributed.sharding.rw_sharding.RwPooledEmbeddingDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.rw_sharding.RwSparseFeaturesDist.training">(torchrec.distributed.sharding.rw_sharding.RwSparseFeaturesDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwPooledEmbeddingDist.training">(torchrec.distributed.sharding.tw_sharding.InferTwPooledEmbeddingDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.InferTwSparseFeaturesDist.training">(torchrec.distributed.sharding.tw_sharding.InferTwSparseFeaturesDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingDist.training">(torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwSparseFeaturesDist.training">(torchrec.distributed.sharding.tw_sharding.TwSparseFeaturesDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingDist.training">(torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwSparseFeaturesDist.training">(torchrec.distributed.sharding.twrw_sharding.TwRwSparseFeaturesDist attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardableModule.training">(torchrec.distributed.types.ShardableModule attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.types.ShardedModule.training">(torchrec.distributed.types.ShardedModule attribute)</a>
</li>
        <li><a href="torchrec.distributed.html#torchrec.distributed.utils.CopyableMixin.training">(torchrec.distributed.utils.CopyableMixin attribute)</a>
</li>
        <li><a href="torchrec.inference.html#torchrec.inference.modules.PredictModule.training">(torchrec.inference.modules.PredictModule attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.DenseArch.training">(torchrec.models.deepfm.DenseArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.FMInteractionArch.training">(torchrec.models.deepfm.FMInteractionArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.OverArch.training">(torchrec.models.deepfm.OverArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.SimpleDeepFMNN.training">(torchrec.models.deepfm.SimpleDeepFMNN attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.deepfm.SparseArch.training">(torchrec.models.deepfm.SparseArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DenseArch.training">(torchrec.models.dlrm.DenseArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM.training">(torchrec.models.dlrm.DLRM attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM_DCN.training">(torchrec.models.dlrm.DLRM_DCN attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRM_Projection.training">(torchrec.models.dlrm.DLRM_Projection attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.DLRMTrain.training">(torchrec.models.dlrm.DLRMTrain attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionArch.training">(torchrec.models.dlrm.InteractionArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionDCNArch.training">(torchrec.models.dlrm.InteractionDCNArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.InteractionProjectionArch.training">(torchrec.models.dlrm.InteractionProjectionArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.OverArch.training">(torchrec.models.dlrm.OverArch attribute)</a>
</li>
        <li><a href="torchrec.models.html#torchrec.models.dlrm.SparseArch.training">(torchrec.models.dlrm.SparseArch attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.activation.SwishLayerNorm.training">(torchrec.modules.activation.SwishLayerNorm attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.CrossNet.training">(torchrec.modules.crossnet.CrossNet attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.LowRankCrossNet.training">(torchrec.modules.crossnet.LowRankCrossNet attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.LowRankMixtureCrossNet.training">(torchrec.modules.crossnet.LowRankMixtureCrossNet attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.crossnet.VectorCrossNet.training">(torchrec.modules.crossnet.VectorCrossNet attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.deepfm.DeepFM.training">(torchrec.modules.deepfm.DeepFM attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.deepfm.FactorizationMachine.training">(torchrec.modules.deepfm.FactorizationMachine attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollection.training">(torchrec.modules.embedding_modules.EmbeddingBagCollection attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface.training">(torchrec.modules.embedding_modules.EmbeddingBagCollectionInterface attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollection.training">(torchrec.modules.embedding_modules.EmbeddingCollection attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.embedding_modules.EmbeddingCollectionInterface.training">(torchrec.modules.embedding_modules.EmbeddingCollectionInterface attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.BaseFeatureProcessor.training">(torchrec.modules.feature_processor.BaseFeatureProcessor attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.BaseGroupedFeatureProcessor.training">(torchrec.modules.feature_processor.BaseGroupedFeatureProcessor attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedModule.training">(torchrec.modules.feature_processor.PositionWeightedModule attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.feature_processor.PositionWeightedProcessor.training">(torchrec.modules.feature_processor.PositionWeightedProcessor attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.mlp.MLP.training">(torchrec.modules.mlp.MLP attribute)</a>
</li>
        <li><a href="torchrec.modules.html#torchrec.modules.mlp.Perceptron.training">(torchrec.modules.mlp.Perceptron attribute)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingBagCollection.training">(torchrec.quant.embedding_modules.EmbeddingBagCollection attribute)</a>
</li>
        <li><a href="torchrec.quant.html#torchrec.quant.embedding_modules.EmbeddingCollection.training">(torchrec.quant.embedding_modules.EmbeddingCollection attribute)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.ComputeKJTToJTDict.training">(torchrec.sparse.jagged_tensor.ComputeKJTToJTDict attribute)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipeline">TrainPipeline (class in torchrec.distributed.train_pipeline)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineBase">TrainPipelineBase (class in torchrec.distributed.train_pipeline)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineContext">TrainPipelineContext (class in torchrec.distributed.train_pipeline)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.train_pipeline.TrainPipelineSparseDist">TrainPipelineSparseDist (class in torchrec.distributed.train_pipeline)</a>
</li>
      <li><a href="torchrec.datasets.html#torchrec.datasets.criteo.BinaryCriteoUtils.tsv_to_npys">tsv_to_npys() (torchrec.datasets.criteo.BinaryCriteoUtils static method)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twcw_sharding.TwCwPooledEmbeddingSharding">TwCwPooledEmbeddingSharding (class in torchrec.distributed.sharding.twcw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingDist">TwPooledEmbeddingDist (class in torchrec.distributed.sharding.tw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwPooledEmbeddingSharding">TwPooledEmbeddingSharding (class in torchrec.distributed.sharding.tw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingDist">TwRwPooledEmbeddingDist (class in torchrec.distributed.sharding.twrw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwPooledEmbeddingSharding">TwRwPooledEmbeddingSharding (class in torchrec.distributed.sharding.twrw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.twrw_sharding.TwRwSparseFeaturesDist">TwRwSparseFeaturesDist (class in torchrec.distributed.sharding.twrw_sharding)</a>
</li>
      <li><a href="torchrec.distributed.sharding.html#torchrec.distributed.sharding.tw_sharding.TwSparseFeaturesDist">TwSparseFeaturesDist (class in torchrec.distributed.sharding.tw_sharding)</a>
</li>
      <li><a href="torchrec.inference.html#torchrec.inference.modules.BatchingMetadata.type">type (torchrec.inference.modules.BatchingMetadata attribute)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.PartitionByType.UNIFORM">UNIFORM (torchrec.distributed.planner.types.PartitionByType attribute)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.proposers.UniformProposer">UniformProposer (class in torchrec.distributed.planner.proposers)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="V">V</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.datasets.html#torchrec.datasets.utils.val_filter">val_filter() (in module torchrec.datasets.utils)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.clipping.GradientClipping.VALUE">VALUE (torchrec.optim.clipping.GradientClipping attribute)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupStage.value">value (torchrec.optim.warmup.WarmupStage attribute)</a>
</li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.values">values() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.values">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedTensor.values">(torchrec.sparse.jagged_tensor.KeyedTensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#id11">variable_batch_size (torchrec.distributed.comm_ops.All2AllSequenceInfo attribute)</a>, <a href="torchrec.distributed.html#torchrec.distributed.comm_ops.All2AllSequenceInfo.variable_batch_size">[1]</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.crossnet.VectorCrossNet">VectorCrossNet (class in torchrec.modules.crossnet)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="W">W</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.distributed.html#torchrec.distributed.types.Awaitable.wait">wait() (torchrec.distributed.types.Awaitable method)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupOptimizer">WarmupOptimizer (class in torchrec.optim.warmup)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupPolicy">WarmupPolicy (class in torchrec.optim.warmup)</a>
</li>
      <li><a href="torchrec.optim.html#torchrec.optim.warmup.WarmupStage">WarmupStage (class in torchrec.optim.warmup)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.weight_init_max">weight_init_max (torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>
</li>
      <li><a href="torchrec.modules.html#torchrec.modules.embedding_configs.BaseEmbeddingConfig.weight_init_min">weight_init_min (torchrec.modules.embedding_configs.BaseEmbeddingConfig attribute)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.weights">weights() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.JaggedTensor.weights_or_none">weights_or_none() (torchrec.sparse.jagged_tensor.JaggedTensor method)</a>

      <ul>
        <li><a href="torchrec.sparse.html#torchrec.sparse.jagged_tensor.KeyedJaggedTensor.weights_or_none">(torchrec.sparse.jagged_tensor.KeyedJaggedTensor method)</a>
</li>
      </ul></li>
      <li><a href="torchrec.distributed.planner.html#torchrec.distributed.planner.types.Topology.world_size">world_size (torchrec.distributed.planner.types.Topology property)</a>
</li>
      <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DataParallelWrapper.wrap">wrap() (torchrec.distributed.model_parallel.DataParallelWrapper method)</a>

      <ul>
        <li><a href="torchrec.distributed.html#torchrec.distributed.model_parallel.DefaultDataParallelWrapper.wrap">(torchrec.distributed.model_parallel.DefaultDataParallelWrapper method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="Z">Z</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torchrec.optim.html#torchrec.optim.fused.EmptyFusedOptimizer.zero_grad">zero_grad() (torchrec.optim.fused.EmptyFusedOptimizer method)</a>

      <ul>
        <li><a href="torchrec.optim.html#torchrec.optim.fused.FusedOptimizer.zero_grad">(torchrec.optim.fused.FusedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.CombinedOptimizer.zero_grad">(torchrec.optim.keyed.CombinedOptimizer method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.KeyedOptimizerWrapper.zero_grad">(torchrec.optim.keyed.KeyedOptimizerWrapper method)</a>
</li>
        <li><a href="torchrec.optim.html#torchrec.optim.keyed.OptimizerWrapper.zero_grad">(torchrec.optim.keyed.OptimizerWrapper method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>



             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Meta.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>